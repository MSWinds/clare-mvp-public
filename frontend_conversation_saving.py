# -*- coding: utf-8 -*-
"""Streamlit Frontend (main.py) with Conversation Saving

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TiejSNC82OFytMi9ZZObbLOgbGH7k1IA
"""

import streamlit as st
from dotenv import load_dotenv
# Import the main LangGraph workflow entry point
from agentic_workflow import get_workflow # Assuming agentic_workflow.py is in the same directory
import asyncio
from langchain_core.tracers.context import collect_runs
# LangSmith Client enables feedback tracking and run tracing (for evaluation, debugging)
from langsmith import Client
from streamlit_feedback import streamlit_feedback
from functools import partial
# Traceback is used to print the full traceback of an error
import traceback
import json # To handle storing chat history as JSON

from sqlalchemy import create_engine, Table, Column, String, Text, MetaData, DateTime
from sqlalchemy.dialects.postgresql import UUID, JSONB # Use JSONB for storing chat history
from sqlalchemy.exc import SQLAlchemyError
from datetime import datetime, timezone
import uuid
import os

# Load environment variables
load_dotenv()

# --- Database Setup ---
connection_string = os.getenv("DB_CONNECTION")
if not connection_string:
    st.error("DB_CONNECTION environment variable not set. Cannot connect to database.")
    st.stop() # Stop execution if DB connection is missing

try:
    engine = create_engine(connection_string)
    metadata = MetaData()

    # Define table structure for INDIVIDUAL chat messages (existing)
    chat_table = Table(
        'chat_history', metadata,
        Column('id', UUID(as_uuid=True), primary_key=True, default=uuid.uuid4),
        Column('conversation_id', UUID(as_uuid=True), nullable=False), # Link to full conversation
        Column('student_id', Text, nullable=False),
        Column('role', String(10), nullable=False), # 'user' or 'ai'
        Column('user_input', Text), # User's message text
        Column('ai_response', Text), # AI's message text (can be null for user rows)
        Column('run_id', String), # Langsmith run_id for AI messages
        Column('timestamp', DateTime(timezone=True), default=datetime.now(timezone.utc))
    )

    # Define table structure for FULL conversations
    full_conversation_table = Table(
        'full_conversations', metadata,
        Column('conversation_id', UUID(as_uuid=True), primary_key=True, default=uuid.uuid4),
        Column('student_id', Text, nullable=False),
        Column('conversation_data', JSONB, nullable=False), # Store the list of chat messages
        Column('start_time', DateTime(timezone=True), default=datetime.now(timezone.utc)),
        Column('end_time', DateTime(timezone=True)) # Will be set when saving
    )

    # Create tables if they don't exist
    metadata.create_all(engine)
    print("Database tables checked/created successfully.")

except SQLAlchemyError as e:
    st.error(f"Database connection or table creation failed: {e}")
    print(f"Database error: {e}")
    st.stop() # Stop execution on DB error

# --- Database Interaction Functions ---

def store_individual_chat_to_db(conversation_id, student_id, role, content, run_id=None):
    """Stores a single message (user or AI) to the chat_history table."""
    try:
        with engine.connect() as conn:
            insert_stmt = chat_table.insert().values(
                id=uuid.uuid4(),
                conversation_id=conversation_id,
                student_id=student_id,
                role=role,
                user_input=content if role == 'human' else None,
                ai_response=content if role == 'ai' else None,
                run_id=run_id if role == 'ai' else None,
                timestamp=datetime.now(timezone.utc)
            )
            conn.execute(insert_stmt)
            conn.commit()
            # print(f"Stored individual message for conv {conversation_id}") # Less verbose logging
    except SQLAlchemyError as e:
        print(f"Failed to insert individual chat into DB: {e}")
        st.warning("Could not save message to database.") # Inform user non-critically

def store_full_conversation_to_db(conversation_id, student_id, chat_history):
    """Stores the entire chat history list as a JSONB entry."""
    if not student_id or not chat_history:
        print("Skipping saving full conversation: Missing student ID or chat history.")
        return # Don't save if essential info is missing

    try:
        with engine.connect() as conn:
            # Check if conversation_id already exists to perform an UPSERT
            select_stmt = full_conversation_table.select().where(full_conversation_table.c.conversation_id == conversation_id)
            result = conn.execute(select_stmt).fetchone()

            end_time = datetime.now(timezone.utc)

            if result:
                # Update existing conversation
                update_stmt = full_conversation_table.update().\
                    where(full_conversation_table.c.conversation_id == conversation_id).\
                    values(
                        conversation_data=json.dumps(chat_history), # Ensure it's JSON string
                        end_time=end_time
                    )
                conn.execute(update_stmt)
                print(f"Updated full conversation {conversation_id} for student {student_id}")
            else:
                # Insert new conversation
                insert_stmt = full_conversation_table.insert().values(
                    conversation_id=conversation_id,
                    student_id=student_id,
                    conversation_data=json.dumps(chat_history), # Ensure it's JSON string
                    # start_time is default, end_time is now
                    end_time=end_time
                )
                conn.execute(insert_stmt)
                print(f"Stored new full conversation {conversation_id} for student {student_id}")

            conn.commit()
    except SQLAlchemyError as e:
        print(f"Failed to store full conversation {conversation_id} into DB: {e}")
        st.error("Failed to save the full conversation history.") # More prominent error for full save
    except TypeError as e:
        print(f"Failed to serialize chat history to JSON for {conversation_id}: {e}")
        st.error("Failed to save conversation due to data format issue.")


# --- LangSmith Client Setup ---
try:
    client = Client()
    print("LangSmith Client Initialized Successfully.")
except Exception as e:
    # Warn once during startup if client initialization fails
    st.warning(f"Could not initialize LangSmith client. Feedback submission may not work. Error: {e}")
    print(f"LangSmith Client Initialization Failed: {e}")
    client = None # Set client to None if initialization fails

# --- Streamlit Page Configuration ---
st.set_page_config(
    page_title='Clare-AI - TA Assistant',
    page_icon="clare_pic.jpg", # Make sure this image exists or remove/replace
    layout="wide"
)

# --- Main Title ---
st.markdown(
    """
    <h1 style='text-align: center; color: #4B8BBE;'>
        üè´üî• <span style='color:#306998;'>Clare-AI</span> - TA Assistant
    </h1>
    """,
    unsafe_allow_html=True
)

# --- Sidebar ---
with st.sidebar:
    # Use session state to keep student ID persistent
    if "student_id" not in st.session_state:
        st.session_state.student_id = ""

    st.session_state.student_id = st.text_input(
        "üìõ Enter Your Student ID",
        value=st.session_state.student_id, # Use value from session state
        key="student_id_input" # Use a different key for the input widget itself
    )

    # Ensure student_id in session state is updated if input changes
    if st.session_state.student_id_input != st.session_state.student_id:
        st.session_state.student_id = st.session_state.student_id_input

    # Display student ID if entered
    if st.session_state.student_id:
        st.markdown(f"**Current Student ID:** {st.session_state.student_id}")
    else:
        st.warning("Please enter your Student ID to save conversations.")

    try:
        st.image("clare_pic-removebg.png", width=150) # Clare logo - ensure file exists
    except Exception:
        st.markdown("*(Logo image not found)*")

    st.markdown("## ü§ñ Clare-AI: Your IST 345 Assistant")
    st.markdown("""
    Welcome to **Clare-AI**, your dedicated assistant for **CGU IST 345.1 ‚Äì Building Generative AI Applications**.

    - üë• **Instructor & TA Contacts**:
    - **Instructor**: Yan Li ‚Äì [Yan.Li@cgu.edu](mailto:Yan.Li@cgu.edu)
    - **TA (Lab Tutoring)**: Kaijie Yu ‚Äì [Kaijie.Yu@cgu.edu](mailto:Kaijie.Yu@cgu.edu)
    - **TA (Data Management)**: Yongjia Sun ‚Äì [Yongjia.Sun@cgu.edu](mailto:Yongjia.Sun@cgu.edu)

    I'm here to support your learning journey by:
    - üìò **Course Materials**: Access lecture notes, reading lists, and assignment guidelines.
    - üß† **Conceptual Understanding**: Get explanations on RNNs, LSTMs, transformers, and other neural network architectures.
    - üõ†Ô∏è **Practical Questions**: Assistance with coding assignments and model implementation.

    **Clare-AI is designed to guide your reasoning process rather than provide direct answers**, helping you develop critical thinking skills. By analyzing your questions and responses, Clare-AI offers feedback to improve your understanding and explore new problem-solving strategies.

    Let's explore the fascinating world of generative AI together!
    """)

    st.markdown("---")
    st.markdown("**Note:** Clicking 'New Conversation' will save your current chat history to the database before starting fresh.")

    # Refresh/Save button
    if st.button("Save & New Conversation üîÑ", use_container_width=True):
        if not st.session_state.student_id:
            st.warning("Please enter your Student ID before starting a new conversation to save the history.")
        else:
            # --- SAVE FULL CONVERSATION ---
            if "chat_history" in st.session_state and st.session_state.chat_history:
                conversation_id_to_save = st.session_state.get("conversation_id", None)
                if conversation_id_to_save:
                     print(f"Attempting to save full conversation {conversation_id_to_save}...")
                     store_full_conversation_to_db(
                         conversation_id_to_save,
                         st.session_state.student_id,
                         st.session_state.chat_history
                     )
                else:
                    print("Warning: No conversation ID found in session state to save.")
            else:
                print("No chat history in session state to save.")
            # --- END SAVE ---

            # Clear chat history for the new conversation
            st.session_state.chat_history = []
            # Generate a *new* conversation ID for the next session
            st.session_state.conversation_id = uuid.uuid4()
            print(f"Starting new conversation with ID: {st.session_state.conversation_id}")

            # Remove all feedback keys from session state
            keys_to_delete = [key for key in st.session_state.keys() if key.startswith("feedback_")]
            for key in keys_to_delete:
                del st.session_state[key]

            # Restart the app to show a fresh interface
            st.rerun()

# --- Initialize Session State ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "conversation_id" not in st.session_state:
    # Generate a unique ID for this chat session when it first starts
    st.session_state.conversation_id = uuid.uuid4()
    print(f"Initialized new conversation with ID: {st.session_state.conversation_id}")


# --- Feedback Submission Function ---
def submit_feedback(user_response, run_id, client):
    """
    Submits thumbs-up/down feedback to LangSmith for a given run ID.
    """
    # If client is None (init failed) or run_id is missing, skip silently.
    if not client or not run_id:
        print(f"Debug (submit_feedback skipped): Client available: {client is not None}, Run ID: {run_id}")
        return

    try:
        # Map emoji score to numeric value expected by LangSmith
        score_map = {"üëç": 1, "üëé": 0}
        score = score_map.get(user_response.get("score"))
        comment = user_response.get("text")

        if score is not None:
            feedback_result = client.create_feedback(
                run_id=run_id,
                key="user_thumb_feedback",       # Descriptive key
                score=score,                     # Numeric score (1 or 0)
                comment=comment,                 # Optional user explanation
                value=user_response.get("score") # Store the emoji
            )
            print(f"Feedback submitted: Run ID: {run_id}, Score: {score}, Comment: {comment}, Result: {feedback_result}")
        else:
             print(f"Feedback skipped (no score): Run ID: {run_id}, Response: {user_response}")

    except Exception as e:
        st.error(f"Failed to submit feedback to LangSmith: {e}")
        print(f"Error submitting feedback: Run ID: {run_id}, Exception: {e}")

# --- Async function to get LLM response AND LangSmith run_id ---
async def get_drucker_response_with_run_id(user_input):
    """
    Executes the LangGraph workflow and captures the AI response and LangSmith run ID.
    """
    graph = get_workflow().compile()
    final_state = None
    run_id = None
    ai_response_content = "I'm sorry, I couldn't find a good answer. Could you try rephrasing?"

    # Ensure student ID is available for potential use within the workflow if needed
    # student_id = st.session_state.get("student_id", "unknown_streamlit_user")

    with collect_runs() as cb:
        try:
            # Input for the graph now includes the question
            graph_input = {"question": user_input}
            # Potentially add other state if your graph needs it, e.g.:
            # graph_input["student_id"] = student_id
            # graph_input["conversation_id"] = st.session_state.conversation_id

            async for event in graph.astream(
                graph_input,
                stream_mode="values",
                config={"tags": ["streamlit_app_call"]}
                ):
                final_state = event

            if final_state and "generation" in final_state:
                 ai_response_content = final_state["generation"]
            else:
                 print(f"Final state missing 'generation': {final_state}")

            if cb.traced_runs:
                run_id = str(cb.traced_runs[-1].id)
            else:
                 print("Warning: No runs traced by collect_runs.")

        except Exception as e:
            ai_response_content = f"An error occurred: {e}. Please check logs."
            print(f"Error during graph execution: {e}")
            traceback.print_exc()

    return ai_response_content, run_id

# --- Feedback Widget Creation Helper ---
def create_feedback_widget(feedback_key, run_id, client, disable_with_score=None):
    """Creates a standardized feedback widget."""
    return streamlit_feedback(
        feedback_type="thumbs",
        optional_text_label="Provide feedback",
        key=feedback_key,
        on_submit=partial(submit_feedback, run_id=run_id, client=client),
        kwargs={"run_id": run_id, "client": client},
        disable_with_score=disable_with_score,
    )

# --- Chat Display and Feedback UI ---
# Loop over each message in the stored chat history
for i, message in enumerate(st.session_state.chat_history):
    role = message["role"]          # 'human' or 'ai'
    content = message["content"]    # Message text
    run_id = message.get("run_id")  # LangSmith run ID for AI messages

    with st.chat_message(role):
        st.markdown(content)

    # Add feedback widget for AI messages if run_id exists
    if role == "ai" and run_id:
        feedback_key = f"feedback_{i}"
        if feedback_key not in st.session_state:
            st.session_state[feedback_key] = None

        current_feedback = st.session_state.get(feedback_key)
        score_to_disable_with = current_feedback.get("score") if current_feedback else None

        create_feedback_widget(feedback_key, run_id, client, score_to_disable_with)

    # Display warning only if run_id is missing for an AI message
    elif role == "ai" and not run_id:
         st.warning("Feedback not available for this message (missing run ID).", icon="‚ö†Ô∏è")


# --- Initial Greeting ---
if not st.session_state.chat_history:
    with st.chat_message("ai"):
        st.write("Hello, I'm Clare-AI - TA Assistant. How can I help you today? üòä")
        # Optionally add this initial greeting to history if you want it saved
        # initial_greeting = {"role": "ai", "content": "Hello, I'm Clare-AI - TA Assistant. How can I help you today? üòä", "run_id": None}
        # st.session_state.chat_history.append(initial_greeting)
        # store_individual_chat_to_db(st.session_state.conversation_id, st.session_state.get("student_id", "unknown"), "ai", initial_greeting["content"])


# --- User Input Processing ---
user_query = st.chat_input("Ask about Class info...")

if user_query:
    current_student_id = st.session_state.get("student_id", None)
    if not current_student_id:
        st.warning("Please enter your Student ID in the sidebar to continue the conversation.", icon="‚ö†Ô∏è")
    else:
        # Append and store user message
        st.session_state.chat_history.append({"role": "human", "content": user_query})
        store_individual_chat_to_db(st.session_state.conversation_id, current_student_id, "human", user_query)

        # Display User Input
        with st.chat_message("human"):
            st.markdown(user_query)

        # AI Response Generation
        with st.chat_message("ai"):
            message_placeholder = st.empty()
            run_id = None

            # Display Loading Indicator
            with message_placeholder.status("Consulting CGU databases..."):
                try:
                    # Ensure asyncio event loop is handled correctly in Streamlit
                    # Use asyncio.run() which manages the loop lifecycle
                    ai_response_content, run_id = asyncio.run(get_drucker_response_with_run_id(user_query))
                except RuntimeError as e:
                     if "cannot run current event loop" in str(e):
                         # If running in a context where asyncio.run() is problematic (like certain Streamlit setups or threads)
                         # try getting the existing loop or creating a new one.
                         loop = asyncio.get_event_loop()
                         ai_response_content, run_id = loop.run_until_complete(get_drucker_response_with_run_id(user_query))
                     else:
                         raise # Re-raise other runtime errors
                except Exception as e:
                     st.error(f"Error generating response: {e}")
                     print(f"Error in get_drucker_response_with_run_id call: {e}")
                     ai_response_content = "Sorry, I encountered an error generating the response."

            # Display AI Response
            message_placeholder.markdown(ai_response_content)

            # Append and store AI message
            ai_message_data = {"role": "ai", "content": ai_response_content, "run_id": run_id}
            st.session_state.chat_history.append(ai_message_data)
            store_individual_chat_to_db(st.session_state.conversation_id, current_student_id, "ai", ai_response_content, run_id)


            # Render feedback widget if run_id was obtained
            if run_id:
                new_message_index = len(st.session_state.chat_history) - 1
                feedback_key = f"feedback_{new_message_index}"
                if feedback_key not in st.session_state:
                     st.session_state[feedback_key] = None
                create_feedback_widget(feedback_key, run_id, client)
            elif not run_id:
                 st.warning("Feedback not available for this message (missing run ID).", icon="‚ö†Ô∏è")

        print("--- Finished Processing User Query ---")