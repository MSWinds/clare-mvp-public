{"cells":[{"cell_type":"markdown","metadata":{"id":"kAoRHlJCYr3g"},"source":["# Lab 2 - Evaluating Foundation Models with LangChain\n","In this lab, we evaluate the foundation models using two patient cases.\n","\n","We will explore different evaluation approaches and compare the responses of GPT-4o and Gemini-2.0-flash.\n","\n","We will experiment the following four approaches when labeled groud-truth data is available:\n","1. Production efficiency  \n","2. Semantic similarity  \n","3. AI as a judge\n","4. NLP-based Metrics"]},{"cell_type":"markdown","source":["## 1 Set up the enviroment\n","\n","\n"],"metadata":{"id":"7zrYB-odMbKY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWSSK1mdYr3i"},"outputs":[],"source":["# Install required packages in silent mode\n","%pip install -U -q langchain-together langchain-google-genai tabulate nltk rouge-score scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLtd3LFaYr3j"},"outputs":[],"source":["# Load required packages\n","from dotenv import load_dotenv\n","import pandas as pd\n","import numpy as np\n","import os\n","from IPython.display import Markdown\n","from tabulate import tabulate\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_core.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","from langchain.schema import SystemMessage, HumanMessage\n","from langchain.evaluation import load_evaluator\n","from langchain_together import ChatTogether\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","import time\n","from contextlib import contextmanager"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4UhOpd8Yr3j"},"outputs":[],"source":["# Load environment variables from a .env file\n","load_dotenv()\n","\n","# Access your API Keys\n","openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n","together_api_key = os.getenv(\"TOGETHER_API_KEY\")\n","google_api_key = os.getenv(\"GEMINI_API_KEY\")"]},{"cell_type":"markdown","source":["## 2 Initialize models\n","We initialize three foundation models. DeepSeek-V3 will be used as an AI judge."],"metadata":{"id":"jzPhMYSnOm34"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOnO8ICtYr3k"},"outputs":[],"source":["# Initialize the GPT-4o model from OpenAI\n","llm_gpt = ChatOpenAI(\n","    model_name=\"gpt-4o\",\n","    temperature=0,\n","    max_retries=2,\n","    timeout= 120, # Sets a request timeout of 120 seconds\n","    openai_api_key=openai_api_key)\n","\n","# Initialize the DeepSeek-V3 using Together API\n","llm_deepseek = ChatTogether(\n","    model=\"deepseek-ai/DeepSeek-V3\",\n","    temperature=0,\n","    max_retries=2,\n","    timeout= 120,\n","    together_api_key= together_api_key\n",")\n","\n","# Initialize the Google Gemini-2.0-Flash model\n","llm_google = ChatGoogleGenerativeAI(\n","    model=\"gemini-2.0-flash\",\n","    temperature=0,\n","    max_retries=2,\n","    timeout= 120,\n","    google_api_key= google_api_key\n",")"]},{"cell_type":"markdown","source":["## 3 Define system prompt and cases\n","*   The system prompt mimics an clinic pharmacist specializing in MTM.\n","*   Each case has two questions (see case background)  "],"metadata":{"id":"X59AdDyXQ8A_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Id34xNG4Yr3k"},"outputs":[],"source":["# Define the system prompt\n","system_prompt_template = PromptTemplate.from_template(\"\"\"\n","You are an experienced clinical pharmacist specializing in Medication Therapy Management (MTM).\n","Provide a clear, honest, and well-structured response in a single paragraph, including key details based on the following scenario.\n","This is a hypothetical case for educational and testing purposes only.\n","Case Scenario: {scenario}\n","\"\"\")\n","# Prompt engineering strategies may vary among different models.\n"]},{"cell_type":"markdown","metadata":{"id":"K0yWFoOjYr3k"},"source":["### Case 1\n","This is a relatively simple case."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6m4dMljKYr3k"},"outputs":[],"source":["# Define the case scenario\n","case1 = \"\"\"\n","Scenario:\n","Mrs. Johnson is a 65-year-old woman recently diagnosed with hypertension.\n","She has been prescribed Lisinopril 10 mg once daily.\n","She reports feeling well and is compliant with her medication.\n","During her routine check-up, her blood pressure was recorded at 142/88 mmHg.\n","\n","Medical Assessment:\n","- **Primary Medical Concerns:**\n","  - Patient reports feeling well and is compliant with her medication.\n","  - Blood pressure reading: 142/88 mmHg.\n","\n","- **Past Medical History (PMH):**\n","  - Hypertension.\n","\n","- **Allergies:**\n","  - None.\n","\n","- **Current Medications:**\n","  - Lisinopril 10 mg once daily.\n","\"\"\"\n","\n","# Format the system prompt\n","case1_system_prompt = system_prompt_template.format(scenario=case1)"]},{"cell_type":"markdown","source":["#### Question 1"],"metadata":{"id":"hdhAg51JVGjQ"}},{"cell_type":"code","source":["# Define the question 1\n","case1_question1 = \"Are there any significant drug-drug interactions?\"\n","\n","# Define the ground truth answer\n","case1_ground_truth1 = \"\"\"\n","No drug-drug interactions\n","\"\"\""],"metadata":{"id":"dSjUL92CU1mV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Question 2"],"metadata":{"id":"kngFCGAbVKUp"}},{"cell_type":"code","source":["# Second question\n","case1_question2 = \"Which medication changes should be made based on the patient's conditions?\"\n","\n","# Define the ground truth answer from expert\n","case1_ground_truth2 = \"\"\"\n","Increase lisinopril to 20 mg once daily,\n","since blood pressure is not well controlled a change to the current regimen is recommended.\n","Increasing the dose of lisinopril should be effective in controlling blood pressure.\n","\"\"\""],"metadata":{"id":"GzG-RkkmTN9R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Case 2\n","This is a more complex case."],"metadata":{"id":"2ppPxrnvVSyY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHiD2gtgYr3n"},"outputs":[],"source":["case2 = \"\"\"\n","Scenario:\n","ME is a 41-year-old man diagnosed with HIV approximately 6 years ago.\n","He is on antiretroviral therapy and was recently diagnosed with diabetes and hypertension.\n","After starting new medications, he developed significant fatigue, nausea, and physical changes.\n","He presented to the emergency department with these symptoms approximately 2 weeks after starting new medications.\n","\n","Medical Assessment\n","- **Primary Medical Concerns:**\n","  - Patient presents with significant fatigue and nausea\n","  - Physical examination reveals purple stretch marks, small bruises\n","  - Development of moon face and shoulder hump\n","  - Reports difficulty breathing and wheezing, worsened by physical activity\n","\n","- **Past Medical History (PMH):**\n","  - HIV (diagnosed 6 years ago)\n","  - Diabetes (recently diagnosed)\n","  - Hypertension (recently diagnosed)\n","  - Asthma\n","\n","- **Allergies:**\n","  - None\n","\n","- **Current Medications:**\n","  - Darunavir/cobicistat (Prezcobix)\n","  - Dolutegravir (Tivicay)\n","  - Metformin 500 mg twice daily\n","  - Lisinopril 5 mg daily\n","  - Fluticasone\n","  - Albuterol\n","\"\"\"\n","\n","case2_system_prompt = system_prompt_template.format(scenario=case2)\n"]},{"cell_type":"markdown","source":["#### Question 1"],"metadata":{"id":"P9_iN9D9Vr46"}},{"cell_type":"code","source":["case2_question1 = \"Are there any significant drug-drug interactions?\"\n","\n","case2_ground_truth1 = \"\"\"\n","-Inhaled corticosteroids (fluticasone) and pharmacokinetic boosters (darunavir/cobicistat) are known to interact.\n","ME’s reaction originated from a cytochrome P450 3A4 interaction between cobicistat and fluticasone.\n","The interaction increases cortisol levels within the body while inhibiting its clearance, leading to adrenal suppression.\n","As a result, ME developed Cushing syndrome. Bruising easily, a fatty hump between the shoulders, and moon facies are common presentations of the disease.\n","Patients with HIV are susceptible to a considerable number of drug interactions, because they are likely to develop comorbidities as they age.\n","It is important to review a patient’s medical history before initiating new medications.\n","-Dolutegravir (Tivicay) may increase the serum concentration of Metformin.\n","\"\"\""],"metadata":{"id":"mLAFH0zCVt7c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Question 2"],"metadata":{"id":"6GU1HxyIWLAr"}},{"cell_type":"code","source":["case2_question2 = \"Which medication changes should be made based on the patient's conditions?\"\n","\n","case2_ground_truth2 = \"\"\"\n","To avoid this reaction, the preferred alternative to fluticasone is beclomethasone, this therapy is preferred since there is minimal interaction with current HIV regimen (Category B: No action needed).\n","- This regimen follows asthma guidelines (2020) stating this patient requires a step up in therapy (Step 2) to better control asthma symptoms. Preferred choice is Daily low-dose ICS and PRN SABA or PRN concomitant ICS and SABA.\n","- To manage interaction of Dolutegravir (Tivicay) and Metformin consider a lower metformin dose to prevent toxicities like lactic acidosis. Given that Metformin is the first line therapy for diabetes management, per ADA, therapy should be continued.\n","\n","\"\"\""],"metadata":{"id":"BU5YBzf2WKYl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NvviNtmBYr3l"},"source":["## 4 Response generation and efficiency evaluation\n","This step generate responses to different questions and compare their efficiencies using the two metrics below:  \n","\n","- **Inference Cost:** The cost associated with running an LLM to generate responses.\n","- **Response Time:**  \n","       ``Response Time`` = ``end_time`` - ``start_time``"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pfhVniYKYr3k"},"outputs":[],"source":["# Define a class to track the usage of the model\n","class ModelUsageTracker:\n","    def __init__(self, price_per_1m_tokens):\n","        \"\"\"\n","        Initializes a tracker for monitoring API usage.\n","\n","        Parameters:\n","        - price_per_1m_tokens: Defines the $ cost per 1 million tokens.\n","            - Example 1: Separate input/output pricing: {\"input\": 10, \"output\": 30}\n","            - Example 2: A single flat rate for all tokens: 20\n","\n","        Attributes:\n","        - start_time: timestamp when the API call starts.\n","        - end_time: timestamp when the API call ends.\n","        - prompt_tokens: number of input tokens used.\n","        - completion_tokens: number of output tokens generated.\n","        - total_tokens: sum of prompt and completion tokens.\n","        - total_cost: Cost calculated based on token usage.\n","\n","        \"\"\"\n","        self.price_per_1m_tokens = price_per_1m_tokens\n","        self.start_time = None\n","        self.end_time = None\n","        self.prompt_tokens = 0\n","        self.completion_tokens = 0\n","        self.total_tokens = 0\n","        self.total_cost = 0.0\n","        self.response_time = 0.0\n","\n","    def track_usage(self, usage):\n","        \"\"\"\n","        Extracts token usage from API response and calculates the cost.\n","        \"\"\"\n","        if usage:\n","            # Extract input (prompt) and output (completion) tokens\n","            self.prompt_tokens = usage.get(\"prompt_tokens\", usage.get(\"input_tokens\", 0))\n","            self.completion_tokens = usage.get(\"completion_tokens\", usage.get(\"output_tokens\", 0))\n","            self.total_tokens = usage.get(\"total_tokens\", self.prompt_tokens + self.completion_tokens)\n","\n","            # Calculate the total cost based on pricing\n","            if isinstance(self.price_per_1m_tokens, dict):  # Separate princing for input/output tokens\n","                input_cost = (self.prompt_tokens / 1_000_000) * self.price_per_1m_tokens.get(\"input\", 0)\n","                output_cost = (self.completion_tokens / 1_000_000) * self.price_per_1m_tokens.get(\"output\", 0)\n","                self.total_cost = input_cost + output_cost\n","            elif isinstance(self.price_per_1m_tokens, (int, float)):  # Flat-rate pricing\n","                self.total_cost = (self.total_tokens / 1_000_000) * self.price_per_1m_tokens\n","\n","    def get_summary(self):\n","        \"\"\"\n","        Return a dictionary with tracked details.\n","        \"\"\"\n","        return {\n","            \"Prompt Tokens\": self.prompt_tokens,\n","            \"Completion Tokens\": self.completion_tokens,\n","            \"Total Tokens\": self.total_tokens,\n","            \"Total Cost (USD)\": round(self.total_cost, 6),\n","            \"Response Time (s)\": round(self.response_time, 2)\n","        }\n","\n","    def display_summary(self):\n","        \"\"\"\n","        Display usage summary in plain text format.\n","        \"\"\"\n","        print(f\"\"\"\n","------------------------------------------------------------\n","Model Usage Summary\n","------------------------------------------------------------\n","- Prompt Tokens:      {self.prompt_tokens}\n","- Completion Tokens:  {self.completion_tokens}\n","- Total Tokens:       {self.total_tokens}\n","- Total Cost: $       {self.total_cost:.6f}\n","- Response Time:      {self.response_time:.2f} seconds\n","\"\"\")\n","\n","# Define a context manager to automatically track API call usage\n","@contextmanager\n","def usage_tracker(price_per_1m_tokens):\n","    \"\"\"\n","    Context manager for tracking model usage, response time, and cost.\n","      - Automatically starts tracking before API call.\n","      - Stops tracking after API call completes and calculates response time.\n","      - Displays usage summary upon exit.\n","    \"\"\"\n","    tracker = ModelUsageTracker(price_per_1m_tokens)\n","    tracker.start_time = time.time()  # Record start time before API call\n","    yield tracker  # Provide the tracker instance\n","    tracker.end_time = time.time()  # Record end time after API call\n","    tracker.response_time = tracker.end_time - tracker.start_time # Compute response time\n","    # Display usage summary\n","    tracker.display_summary()"]},{"cell_type":"markdown","source":["### Case 1 Question 1"],"metadata":{"id":"Ca17sdxSZIz3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RHADg0_Yr3l","outputId":"6e4b4361-0d20-44b9-901c-543c5947332b"},"outputs":[{"data":{"text/markdown":["In this scenario, Mrs. Johnson is currently taking only Lisinopril 10 mg once daily, and there are no other medications mentioned that could interact with it. Therefore, based on the information provided, there are no drug-drug interactions to consider. However, it is important to be aware that Lisinopril, an ACE inhibitor, can interact with other medications if they are introduced in the future. Common interactions include nonsteroidal anti-inflammatory drugs (NSAIDs), which can reduce the antihypertensive effect of Lisinopril, and potassium supplements or potassium-sparing diuretics, which can increase the risk of hyperkalemia. It is crucial to review any new medications or supplements with a healthcare provider to avoid potential interactions."],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","------------------------------------------------------------\n","Model Usage Summary\n","- Prompt Tokens: 231\n","- Completion Tokens: 153\n","- Total Tokens: 384\n","- Total Cost: $0.002107\n","- Response Time: 3.31 seconds\n","\n"]}],"source":["# GPT4o\n","# Step 1: Initialize a list to store model usage data for analysis\n","gpt_case1_usages1 = []\n","\n","# Step 2: Use the `usage_tracker` context manager to track API call usage\n","with usage_tracker({\"input\": 2.50, \"output\": 10.00}) as tracker_gpt:\n","    \"\"\"\n","    Pricing: $2.50 per 1M input tokens, $10.00 per 1M output tokens.\n","    \"\"\"\n","\n","    # Step 3: Define the input messages\n","    messages = [\n","        SystemMessage(content=case1_system_prompt),\n","        HumanMessage(content=case1_question1)\n","    ]\n","\n","    # Step 4: Invoke the GPT-4o model\n","    case1_gpt_response1 = llm_gpt.invoke(messages)\n","\n","    # Step 5: Display the response in Markdown format\n","    display(Markdown(case1_gpt_response1.content))\n","\n","    # Step 6: Track token usage from the response\n","    tracker_gpt.track_usage(case1_gpt_response1.response_metadata[\"token_usage\"])\n","\n","# Step 7: Capture the final summary and store it in the list\n","gpt_case1_usages1.append(tracker_gpt.get_summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tEp18ZO0Yr3l","outputId":"706af862-fc71-4d14-9733-df4a6b49e7fa"},"outputs":[{"data":{"text/markdown":["Based on the provided information, the patient is currently only taking Lisinopril. Therefore, there are no drug-drug interactions to assess at this time. However, it is crucial to consider potential interactions if any new medications, including over-the-counter drugs or supplements, are added to her regimen in the future."],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","------------------------------------------------------------\n","Model Usage Summary\n","- Prompt Tokens: 245\n","- Completion Tokens: 66\n","- Total Tokens: 311\n","- Total Cost: $0.000051\n","- Response Time: 0.92 seconds\n","\n"]}],"source":["# Google Gemini\n","gemini_case1_usages1 = []\n","\n","with usage_tracker({\"input\": 0.1, \"output\": 0.4}) as tracker_gemini: # Currently free of charge for free tier users\n","    messages = [\n","        SystemMessage(content=case1_system_prompt),\n","        HumanMessage(content=case1_question1)\n","    ]\n","    case1_gemini_response1 = llm_google.invoke(messages)\n","\n","    display(Markdown(case1_gemini_response1.content))\n","\n","    tracker_gemini.track_usage(case1_gemini_response1.usage_metadata)\n","\n","gemini_case1_usages1.append(tracker_gemini.get_summary())"]},{"cell_type":"markdown","source":["### Case 1 Question 2"],"metadata":{"id":"ptqQ6ddvZOX6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"f8IhmPT_Yr3m","outputId":"6718a911-594b-4378-ada5-92b6ec028209"},"outputs":[{"data":{"text/plain":["'GPT4o response:'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["In assessing Mrs. Johnson's current condition, her blood pressure reading of 142/88 mmHg indicates that while her systolic pressure is slightly above the target range for most patients with hypertension, her diastolic pressure is within an acceptable range. Given that she is compliant with her Lisinopril 10 mg once daily and reports feeling well, it may be beneficial to consider a slight adjustment to her medication regimen to achieve better blood pressure control. One option could be to increase the dose of Lisinopril to 20 mg once daily, as this is a common next step in managing hypertension when the initial dose is insufficient. However, before making any changes, it is important to evaluate her overall cardiovascular risk, kidney function, and any potential side effects she may experience with a higher dose. Additionally, lifestyle modifications such as dietary changes, increased physical activity, and weight management should be reinforced as part of her comprehensive hypertension management plan. It is crucial to monitor her blood pressure closely following any medication adjustment to ensure efficacy and safety."],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","------------------------------------------------------------\n","Model Usage Summary\n","- Prompt Tokens: 235\n","- Completion Tokens: 209\n","- Total Tokens: 444\n","- Total Cost: $0.002678\n","- Response Time: 7.22 seconds\n","\n"]},{"data":{"text/plain":["'--------------------------------'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Gemini response:'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["Given Mrs. Johnson's blood pressure reading of 142/88 mmHg despite being compliant with Lisinopril 10mg daily, her hypertension is not currently controlled. As a first step, I would consider increasing the Lisinopril dosage, typically titrating upwards to a maximum of 40mg daily, while closely monitoring her blood pressure and for any signs of hypotension or other side effects like cough or angioedema. If the blood pressure remains uncontrolled with the maximum dose of Lisinopril, or if she experiences intolerable side effects, adding a second antihypertensive medication from a different class, such as a thiazide diuretic (e.g., hydrochlorothiazide) or a calcium channel blocker (e.g., amlodipine), would be the next appropriate step, while also reinforcing lifestyle modifications like diet and exercise."],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","------------------------------------------------------------\n","Model Usage Summary\n","- Prompt Tokens: 251\n","- Completion Tokens: 179\n","- Total Tokens: 430\n","- Total Cost: $0.000097\n","- Response Time: 2.25 seconds\n","\n"]}],"source":["# GPT4o\n","display(\"GPT4o response:\")\n","\n","gpt_case1_usages2 = []\n","\n","with usage_tracker({\"input\": 2.50, \"output\": 10.00}) as tracker_gpt:\n","    messages = [\n","        SystemMessage(content=case1_system_prompt),\n","        HumanMessage(content=case1_question2)\n","    ]\n","\n","    case1_gpt_response2 = llm_gpt.invoke(messages)\n","\n","    display(Markdown(case1_gpt_response2.content))\n","\n","    tracker_gpt.track_usage(case1_gpt_response2.response_metadata[\"token_usage\"])\n","\n","gpt_case1_usages2.append(tracker_gpt.get_summary())\n","\n","display(\"--------------------------------\")\n","\n","# Gemini\n","display(\"Gemini response:\")\n","\n","gemini_case1_usages2 = []\n","\n","with usage_tracker({\"input\": 0.1, \"output\": 0.4}) as tracker_gemini:\n","\n","    messages = [\n","        SystemMessage(content=case1_system_prompt),\n","        HumanMessage(content=case1_question2)\n","    ]\n","    case1_gemini_response2 = llm_google.invoke(messages)\n","\n","    display(Markdown(case1_gemini_response2.content))\n","\n","    tracker_gemini.track_usage(case1_gemini_response2.usage_metadata)\n","\n","gemini_case1_usages2.append(tracker_gemini.get_summary())"]},{"cell_type":"markdown","source":["### Case 2 Question 1"],"metadata":{"id":"LpaJZ6YVZy6u"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKlv_j4fYr3n","outputId":"e0a0b38d-27d9-4ed4-b40f-aab4b33dff58"},"outputs":[{"data":{"text/plain":["'GPT4o response:'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["In this scenario, the patient is experiencing symptoms that may be indicative of drug-drug interactions or side effects from his current medication regimen. The combination of darunavir/cobicistat (Prezcobix) and dolutegravir (Tivicay) is generally well-tolerated, but cobicistat, a pharmacokinetic enhancer, can increase the levels of other drugs metabolized by the liver, potentially affecting the metabolism of other medications. Cobicistat can inhibit CYP3A4, which may lead to increased levels of fluticasone, a corticosteroid, potentially causing Cushing's syndrome-like symptoms such as moon face, shoulder hump, and purple stretch marks. This could also explain the patient's fatigue, nausea, and bruising. Additionally, the use of fluticasone with a CYP3A4 inhibitor like cobicistat can exacerbate asthma symptoms due to systemic corticosteroid effects. Metformin and lisinopril are not typically affected by cobicistat, but the patient's new onset of diabetes and hypertension requires careful monitoring. The patient's symptoms warrant a review of his medication regimen, particularly the use of fluticasone, and consideration of alternative asthma management strategies to avoid systemic corticosteroid exposure."],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","------------------------------------------------------------\n","Model Usage Summary\n","- Prompt Tokens: 327\n","- Completion Tokens: 248\n","- Total Tokens: 575\n","- Total Cost: $0.003298\n","- Response Time: 4.76 seconds\n","\n"]},{"data":{"text/plain":["'--------------------------------'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Gemini response:'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["Given the patient's presentation of fatigue, nausea, purple stretch marks, easy bruising, moon face, shoulder hump, difficulty breathing, and wheezing, in the context of newly diagnosed diabetes and hypertension, and recent initiation of multiple medications including Darunavir/cobicistat, Dolutegravir, Metformin, Lisinopril, Fluticasone, and Albuterol, a strong suspicion for drug-induced Cushing's syndrome arises, most likely from the inhaled fluticasone potentiated by the cobicistat component of Prezcobix. Cobicistat is a strong CYP3A4 inhibitor, which can significantly increase the systemic absorption and bioavailability of fluticasone, leading to iatrogenic Cushing's syndrome. While other drug interactions are possible, such as potential interactions between antiretrovirals and metformin, the constellation of symptoms strongly points towards the fluticasone/cobicistat interaction as the primary concern. The patient's asthma treatment should be re-evaluated, and alternative asthma medications that do not have significant interactions with cobicistat should be considered."],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","------------------------------------------------------------\n","Model Usage Summary\n","- Prompt Tokens: 331\n","- Completion Tokens: 220\n","- Total Tokens: 551\n","- Total Cost: $0.000121\n","- Response Time: 2.24 seconds\n","\n"]}],"source":["# GPT4o\n","display(\"GPT4o response:\")\n","\n","gpt_case2_usages1 = []\n","\n","with usage_tracker({\"input\": 2.50, \"output\": 10.00}) as tracker_gpt:\n","    messages = [\n","        SystemMessage(content=case2_system_prompt),\n","        HumanMessage(content=case2_question1)\n","    ]\n","    case2_gpt_response1 = llm_gpt.invoke(messages)\n","\n","    display(Markdown(case2_gpt_response1.content))\n","\n","    tracker_gpt.track_usage(case2_gpt_response1.response_metadata[\"token_usage\"])\n","\n","gpt_case2_usages1.append(tracker_gpt.get_summary())\n","\n","display(\"-------------------------------------------------------------------\")\n","\n","# Gemini\n","display(\"Gemini response:\")\n","\n","gemini_case2_usages1 = []\n","\n","with usage_tracker({\"input\": 0.1, \"output\": 0.4}) as tracker_gemini:\n","    messages = [\n","        SystemMessage(content=case2_system_prompt),\n","        HumanMessage(content=case2_question1)\n","    ]\n","\n","    case2_gemini_response1 = llm_google.invoke(messages)\n","\n","    display(Markdown(case2_gemini_response1.content))\n","\n","    tracker_gemini.track_usage(case2_gemini_response1.usage_metadata)\n","\n","gemini_case2_usages1.append(tracker_gemini.get_summary())"]},{"cell_type":"markdown","source":["### Case 2 Question 2"],"metadata":{"id":"frdbr8zZZ2Zb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"53m1lh9cYr3r","outputId":"bfdb166a-92a3-4578-edd1-8fe46ba7ec77"},"outputs":[{"data":{"text/plain":["'GPT4o response:'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["Based on the patient's presentation and current medication regimen, it is likely that the patient is experiencing symptoms consistent with Cushing's syndrome, potentially due to an interaction between his HIV medications and fluticasone, a corticosteroid. The combination of darunavir/cobicistat (a protease inhibitor and a CYP3A inhibitor) with inhaled fluticasone can lead to increased systemic corticosteroid levels, causing the physical changes and symptoms observed. To address this, it would be prudent to discontinue fluticasone and consider alternative asthma management strategies that do not involve corticosteroids, such as leukotriene receptor antagonists or adjusting the use of albuterol. Additionally, the patient's fatigue and nausea could be related to the new onset of diabetes and hypertension, or side effects from metformin or lisinopril, so monitoring and adjusting these medications as needed, based on blood glucose and blood pressure control, would be advisable. Close follow-up is necessary to reassess symptoms and ensure effective management of all conditions."],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","------------------------------------------------------------\n","Model Usage Summary\n","- Prompt Tokens: 331\n","- Completion Tokens: 204\n","- Total Tokens: 535\n","- Total Cost: $0.002868\n","- Response Time: 4.90 seconds\n","\n"]},{"data":{"text/plain":["'--------------------------------'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Gemini response:'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":["Based on the patient's presentation of fatigue, nausea, purple striae, easy bruising, moon face, shoulder hump, difficulty breathing, and wheezing, along with his history of HIV, diabetes, hypertension, and asthma, the most likely diagnosis is iatrogenic Cushing's syndrome induced by the fluticasone inhaler. The priority is to immediately discontinue the fluticasone inhaler and switch to an alternative asthma management strategy, such as a leukotriene receptor antagonist or increasing the frequency of albuterol use as needed, while closely monitoring his respiratory status. Given the recent diagnoses of diabetes and hypertension, it's also important to re-evaluate the necessity and dosages of metformin and lisinopril, considering potential interactions with the antiretroviral regimen and the impact of Cushing's syndrome on glucose and blood pressure control. Furthermore, assessing cortisol levels would help confirm the diagnosis of Cushing's syndrome."],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","------------------------------------------------------------\n","Model Usage Summary\n","- Prompt Tokens: 337\n","- Completion Tokens: 187\n","- Total Tokens: 524\n","- Total Cost: $0.000109\n","- Response Time: 2.16 seconds\n","\n"]}],"source":["# GPT4o\n","display(\"GPT4o response:\")\n","\n","gpt_case2_usages2 = []\n","\n","with usage_tracker({\"input\": 2.50, \"output\": 10.00}) as tracker_gpt:\n","    messages = [\n","        SystemMessage(content=case2_system_prompt),\n","        HumanMessage(content=case2_question2)\n","    ]\n","\n","    case2_gpt_response2 = llm_gpt.invoke(messages)\n","\n","    display(Markdown(case2_gpt_response2.content))\n","\n","    tracker_gpt.track_usage(case2_gpt_response2.response_metadata[\"token_usage\"])\n","\n","gpt_case2_usages2.append(tracker_gpt.get_summary())\n","\n","display(\"----------------------------------------------------------------------\")\n","\n","# Gemini\n","display(\"Gemini response:\")\n","\n","gemini_case2_usages2 = []\n","\n","with usage_tracker({\"input\": 0.1, \"output\": 0.4}) as tracker_gemini:\n","    messages = [\n","        SystemMessage(content=case2_system_prompt),\n","        HumanMessage(content=case2_question2)\n","    ]\n","\n","    case2_gemini_response2 = llm_google.invoke(messages)\n","\n","    display(Markdown(case2_gemini_response2.content))\n","\n","    tracker_gemini.track_usage(case2_gemini_response2.usage_metadata)\n","\n","gemini_case2_usages2.append(tracker_gemini.get_summary())"]},{"cell_type":"markdown","metadata":{"id":"RU76oWENYr3l"},"source":["## 5 Semantic similarity evaluation\n","This section introduces a metric for measuring semantic similarity.\n","\n","More specifically, we use:\n","- **Cosine Similarity**: measures semantic similarity between model responses and reference answers by comparing their vector representations in embedding space.\n","- It is very sensitive to contextual differences in the text and does not evaluate factual correctness.\n","\n","Its calculation has two steps:\n","1. Covert reference answers and generated responses into vector embeddings using an LLM's embedding model.\n","2. Compute ``cosine similarity``. Closer to 1 means higher similarity.\n","\n","Check other similarity metrics available in LangChain Evaluation Chain class [``EmbeddingDistance``](https://colab.research.google.com/drive/1IA5tkinVfhXx9Vf8h9T1-WkR3RGDEemP#scrollTo=RU76oWENYr3l&line=12&uniqifier=1)."]},{"cell_type":"code","source":["# Initialize the embedding model\n","embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")"],"metadata":{"id":"xftFIBayNxRV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Case 1 Question 1"],"metadata":{"id":"LYdvHZjhfBm9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FajfibMTYr3l","outputId":"a85a0900-8d07-4a30-a209-abf3f63bbc7a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Cosine Similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GPT-4o</td>\n","      <td>0.442333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gemini 2.0 Flash</td>\n","      <td>0.510733</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Model  Cosine Similarity\n","0            GPT-4o           0.442333\n","1  Gemini 2.0 Flash           0.510733"]},"metadata":{},"output_type":"display_data"}],"source":["# Calculate the cosine similarity between the ground truth and the model's response\n","\n","# Step 1: Initialize the evaluator for cosine similarity measurement\n","cosine_evaluator = load_evaluator(\n","    \"embedding_distance\", # Use embedding-based distance evaluation\n","    embeddings=embedding_model, # the embedding model initialized in the previous step\n","    distance_metric=\"cosine\"  # Specifies cosine distance as the metric (default)\n",")\n","\n","# Step 2: Compute cosine similarity for GPT-4o model\n","gpt_case1_cosine_similarity1 = 1 - cosine_evaluator.evaluate_strings(\n","    prediction=case1_gpt_response1.content, # Generated response\n","    reference=case1_ground_truth1           # Ground truth answer\n","    )['score']\n","\n","# Step 3: Compute cosine similarity for Gemini 2.0 Flash model\n","gemini_case1_cosine_similarity1 = 1 - cosine_evaluator.evaluate_strings(\n","    prediction=case1_gemini_response1.content,\n","    reference=case1_ground_truth1\n","    )['score']\n","\n","\n","# Step 4: Store results in a DataFrame for easy visualization\n","case1_cosine_similarities1 = pd.DataFrame({\n","    \"Model\": [\"GPT-4o\", \"Gemini 2.0 Flash\"],\n","    \"Cosine Similarity\": [gpt_case1_cosine_similarity1, gemini_case1_cosine_similarity1]\n","})\n","\n","# Step 5: Display the results\n","display(case1_cosine_similarities1)\n"]},{"cell_type":"markdown","source":["### Case 1 Question 2"],"metadata":{"id":"UYYrSwMlpums"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"V1viv4D1plOs","outputId":"01ebf009-14d5-4f56-b48c-ce27161ff93f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Cosine Similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GPT-4o</td>\n","      <td>0.701854</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gemini 2.0 Flash</td>\n","      <td>0.697518</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Model  Cosine Similarity\n","0            GPT-4o           0.701854\n","1  Gemini 2.0 Flash           0.697518"]},"metadata":{},"output_type":"display_data"}],"source":["gpt_case1_cosine_similarity2 = 1 - cosine_evaluator.evaluate_strings(\n","    prediction=case1_gpt_response2.content,\n","    reference=case1_ground_truth2\n","    )['score']\n","\n","gemini_case1_cosine_similarity2 = 1 - cosine_evaluator.evaluate_strings(\n","    prediction=case1_gemini_response2.content,\n","    reference=case1_ground_truth2\n","    )['score']\n","\n","# Display the cosine similarity\n","case1_cosine_similarities2 = pd.DataFrame({\n","    \"Model\": [\"GPT-4o\", \"Gemini 2.0 Flash\"],\n","    \"Cosine Similarity\": [gpt_case1_cosine_similarity2, gemini_case1_cosine_similarity2]\n","})\n","\n","display(case1_cosine_similarities2)\n"]},{"cell_type":"markdown","source":["### Case 2 Question 1"],"metadata":{"id":"GZ1VvsOIp6NA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rjn7S0KzplOs","outputId":"610d4884-d90c-4230-b2fa-8d215bf0d64e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Cosine Similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GPT-4o</td>\n","      <td>0.781913</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gemini 2.0 Flash</td>\n","      <td>0.763158</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Model  Cosine Similarity\n","0            GPT-4o           0.781913\n","1  Gemini 2.0 Flash           0.763158"]},"metadata":{},"output_type":"display_data"}],"source":["gpt_case2_cosine_similarity1 = 1 - cosine_evaluator.evaluate_strings(\n","    prediction=case2_gpt_response1.content,\n","    reference=case2_ground_truth1\n","    )['score']\n","\n","gemini_case2_cosine_similarity1 = 1 - cosine_evaluator.evaluate_strings(\n","    prediction=case2_gemini_response1.content,\n","    reference=case2_ground_truth1\n","    )['score']\n","\n","# Display the cosine similarity\n","case2_cosine_similarities1 = pd.DataFrame({\n","    \"Model\": [\"GPT-4o\", \"Gemini 2.0 Flash\"],\n","    \"Cosine Similarity\": [gpt_case2_cosine_similarity1, gemini_case2_cosine_similarity1]\n","})\n","\n","display(case2_cosine_similarities1)"]},{"cell_type":"markdown","source":["### Case 2 Question 2"],"metadata":{"id":"R6npRGE8p8QJ"}},{"cell_type":"code","source":["gpt_case2_cosine_similarity2 = 1 - cosine_evaluator.evaluate_strings(\n","    prediction=case2_gpt_response2.content,\n","    reference=case2_ground_truth2\n","    )['score']\n","\n","gemini_case2_cosine_similarity2 = 1 - cosine_evaluator.evaluate_strings(\n","    prediction=case2_gemini_response2.content,\n","    reference=case2_ground_truth2\n","    )['score']\n","\n","case2_cosine_similarities2 = pd.DataFrame({\n","    \"Model\": [\"GPT-4o\", \"Gemini 2.0 Flash\"],\n","    \"Cosine Similarity\": [gpt_case2_cosine_similarity2, gemini_case2_cosine_similarity2]\n","})\n","\n","display(case2_cosine_similarities2)"],"metadata":{"id":"gpEqMhhVqNNM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HO9Sbeg4Yr3l"},"source":["## 6 AI as a judge\n","This section leverage AI as a judge to evaluate responses based on predefined criteria in LangChain.\n","\n","How to prompt an AI judge is similar to how to prompt any AI application. We will experiment the following four criteria based on LangChain's built-in prompt:\n","\n","- **Correctness**: Is the submission correct, accurate, and factual?\n","- **Relevance**: Is the submission referring to a real quote from the text?\n","- **Coherence**: Is the submission coherent, well-structured, and organized?\n","- **Conciseness**: Is the submission concise and to the point?.\n","\n","\n","How to prompt an AI judge is similar to how to prompt any AI application.\n","\n","For a complete list of evaluation criteria, refer to the LangChain [Criteria class](https://python.langchain.com/api_reference/langchain/evaluation/langchain.evaluation.criteria.eval_chain.Criteria.html)\n","and click \"Source Code\" to view each criterion's promot."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KirskoruYr3m"},"outputs":[],"source":["# Step 1: Combine the system prompt (scenario) and question into a single input string\n","# `strip() function removes any leading/trailing spaces from `case1_system_prompt` for cleaner formatting.\n","input_query = f\"{case1_system_prompt.strip()}\\n\\nQuestion:\\n{case1_question1}\"\n","\n","# Step 2: Define custom evaluation criteria based on LangChain’s predefined prompts\n","\n","custom_criteria = {\n","\"CORRECTNESS\": \"Is the submission correct, accurate, and factual?\",\n","\"RELEVANCE\": \"Does the response directly address the question based on the provided scenario?\",\n","\"COHERENCE\": \"Is the submission coherent, well-structured, and organized?\",\n","\"CONCISENESS\": \"Is the submission concise and to the point?\"\n","}"]},{"cell_type":"markdown","source":["### Case 1 Question 1"],"metadata":{"id":"lov8J6Rlq-1H"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"l5oL2YtXYr3m"},"outputs":[],"source":["# GPT4o\n","\n","# Step 1: Initialize a list to store evaluation results\n","gpt_case1_evaluation_results1 = []\n","\n","\n","# Step 2: Loop through each evaluation criterion and assess the response\n","for criterion, description in custom_criteria.items():\n","    \"\"\"\n","    - `criterion`: the name of the evaluation metric (e.g., CORRECTNESS).\n","    - `description`: A brief definition of the criterion, explaining what it evaluates.\n","    \"\"\"\n","\n","    # Load an evaluator for the given criterion\n","    evaluator = load_evaluator(\n","        \"labeled_criteria\",  # Use LangChain's labeled criteria evaluator\n","        criteria={criterion: description}, # Pass the evaluation metric and description\n","        llm=llm_deepseek # Use the DeepSeek model for evaluation\n","        )\n","\n","    # Step 3: Evaluate the response against the ground truth\n","    result = evaluator.evaluate_strings(\n","        prediction=case1_gpt_response1.content, # Model-generated response\n","        input=input_query,  # The full prompt including scenario and question\n","        reference=case1_ground_truth1 # The ground-truth answer\n","    )\n","\n","    # Step 4: Append the results to the list\n","    gpt_case1_evaluation_results1.append({\n","        \"Criterion\": criterion,\n","        \"Score\": result[\"score\"], # Numeric score assigned by the evaluator\n","        \"Reasoning\": result.get(\"reasoning\", \"No reasoning provided\") # Explanation for the score\n","    })\n","\n","# Step 5: Convert the results into a pandas DataFrame\n","gpt_case1_evaluation_results1 = pd.DataFrame(gpt_case1_evaluation_results1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bzcTGI1SYr3m","outputId":"0c2ec112-93d2-4605-f88d-2dc95067613b"},"outputs":[{"name":"stdout","output_type":"stream","text":["╒════╤═════════════╤═════════╤════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╕\n","│    │ Criterion   │   Score │ Reasoning                                                                                                                                                                                                                                                                                                                                                                                                                                                          │\n","╞════╪═════════════╪═════════╪════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╡\n","│  0 │ CORRECTNESS │       1 │ 1. **Understanding the Scenario**: Mrs. Johnson is taking Lisinopril 10 mg once daily for hypertension. She is compliant with her medication and has no other medications listed. Her blood pressure is slightly elevated at 142/88 mmHg.                                                                                                                                                                                                                          │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 2. **Identifying the Question**: The question asks about potential drug-drug interactions in this scenario.                                                                                                                                                                                                                                                                                                                                                        │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 3. **Analyzing the Submission**: The submission correctly states that there are no drug-drug interactions in this specific scenario because Mrs. Johnson is only taking Lisinopril. It also provides additional information about potential interactions if other medications were introduced, such as NSAIDs or potassium supplements.                                                                                                                            │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 4. **Assessing Correctness**: The submission is accurate and factual. It correctly identifies that there are no current drug-drug interactions based on the information provided. The additional information about potential future interactions is also correct and relevant.                                                                                                                                                                                     │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 5. **Comparing with Reference**: The reference confirms that there are no drug-drug interactions in this scenario, which aligns with the submission.                                                                                                                                                                                                                                                                                                               │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 6. **Conclusion**: The submission meets the criteria for correctness.                                                                                                                                                                                                                                                                                                                                                                                              │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ Y                                                                                                                                                                                                                                                                                                                                                                                                                                                                  │\n","├────┼─────────────┼─────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n","│  1 │ RELEVANCE   │       1 │ 1. **Understanding the Question**: The question asks about drug-drug interactions in the context of Mrs. Johnson's current medication, Lisinopril 10 mg once daily. The scenario does not mention any other medications or supplements she is taking.                                                                                                                                                                                                              │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 2. **Analyzing the Submission**: The submission correctly identifies that there are no drug-drug interactions in the current scenario since Mrs. Johnson is only taking Lisinopril. It also provides additional educational information about potential interactions if other medications were introduced in the future, such as NSAIDs or potassium supplements.                                                                                                  │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 3. **Assessing Relevance**: The response directly addresses the question by stating that there are no drug-drug interactions based on the provided scenario. The additional information about potential future interactions, while useful, does not detract from the relevance of the response to the specific question asked.                                                                                                                                     │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 4. **Conclusion**: The submission meets the relevance criterion as it directly answers the question based on the given scenario.                                                                                                                                                                                                                                                                                                                                   │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ Y                                                                                                                                                                                                                                                                                                                                                                                                                                                                  │\n","├────┼─────────────┼─────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n","│  2 │ COHERENCE   │       1 │ 1. **Coherence**: The submission is coherent and well-structured. It begins by directly addressing the question about drug-drug interactions, stating that there are none based on the information provided. It then provides additional relevant information about potential interactions with Lisinopril if other medications are introduced in the future. This structure ensures that the response is clear and logically organized.                           │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 2. **Well-structured**: The response is well-structured, starting with a clear answer to the question and then expanding on related considerations. The use of specific examples (e.g., NSAIDs, potassium supplements) enhances the clarity and usefulness of the response.                                                                                                                                                                                        │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 3. **Organized**: The submission is organized in a logical flow. It first addresses the immediate question, then provides additional context and advice, which is helpful for understanding the broader implications of the scenario.                                                                                                                                                                                                                              │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ Based on this reasoning, the submission meets the criteria for coherence, well-structured, and organized.                                                                                                                                                                                                                                                                                                                                                          │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ Y                                                                                                                                                                                                                                                                                                                                                                                                                                                                  │\n","├────┼─────────────┼─────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n","│  3 │ CONCISENESS │       0 │ 1. **Understanding the Criteria**: The criterion is \"CONCISENESS,\" which means the submission should be brief and to the point, avoiding unnecessary details or elaboration.                                                                                                                                                                                                                                                                                       │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 2. **Analyzing the Submission**: The submission starts by correctly stating that there are no drug-drug interactions in the given scenario, which is concise. However, it then proceeds to discuss potential future interactions with Lisinopril, including NSAIDs and potassium supplements, which are not relevant to the current scenario. This additional information, while accurate, is not necessary for answering the question based on the provided data. │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 3. **Assessing Conciseness**: The submission could be more concise by omitting the discussion of potential future interactions, as they are not pertinent to the current case. The focus should remain solely on the absence of drug-drug interactions in the present scenario.                                                                                                                                                                                    │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ 4. **Conclusion**: The submission does not fully meet the criterion of conciseness because it includes extraneous information that is not required to answer the question based on the given data.                                                                                                                                                                                                                                                                 │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                                                                                                                    │\n","│    │             │         │ N                                                                                                                                                                                                                                                                                                                                                                                                                                                                  │\n","╘════╧═════════════╧═════════╧════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╛\n"]}],"source":["print(tabulate(gpt_case1_evaluation_results1,\n","               headers='keys',\n","               tablefmt='fancy_grid'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MNIJyUquYr3m","outputId":"7d5bce82-a3af-43a7-b3c5-b8d57411c2b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["╒════╤═════════════╤═════════╤═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╕\n","│    │ Criterion   │   Score │ Reasoning                                                                                                                                                                                                                                                                                                                                                                   │\n","╞════╪═════════════╪═════════╪═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╡\n","│  0 │ CORRECTNESS │       1 │ 1. **Understanding the Scenario**: Mrs. Johnson is a 65-year-old woman with hypertension, currently taking Lisinopril 10 mg once daily. Her blood pressure is 142/88 mmHg, and she reports feeling well and being compliant with her medication. The question asks about drug-drug interactions.                                                                            │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ 2. **Analyzing the Submission**: The submission states that there are no drug-drug interactions to assess because the patient is only taking Lisinopril. It also mentions the importance of considering potential interactions if new medications are added in the future.                                                                                                  │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ 3. **Assessing Correctness**: The submission correctly identifies that there are no drug-drug interactions in the current scenario since the patient is only on Lisinopril. This aligns with the reference, which also indicates no drug-drug interactions. The additional advice about future considerations is prudent but not directly relevant to the current question. │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ 4. **Conclusion**: The submission is correct, accurate, and factual based on the provided information and reference.                                                                                                                                                                                                                                                        │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ Y                                                                                                                                                                                                                                                                                                                                                                           │\n","├────┼─────────────┼─────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n","│  1 │ RELEVANCE   │       1 │ Let's evaluate the submission step by step based on the RELEVANCE criterion:                                                                                                                                                                                                                                                                                                │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ 1. **Understanding the Question**: The question asks about drug-drug interactions in the context of Mrs. Johnson's current medications and scenario.                                                                                                                                                                                                                        │\n","│    │             │         │ 2. **Analyzing the Submission**: The submission correctly identifies that Mrs. Johnson is only taking Lisinopril and states that there are no drug-drug interactions to assess at this time. It also appropriately advises considering potential interactions if new medications are added in the future.                                                                   │\n","│    │             │         │ 3. **Relevance to the Scenario**: The response directly addresses the question by focusing on the absence of drug-drug interactions given the current medication regimen. It also provides a relevant and practical consideration for future scenarios.                                                                                                                     │\n","│    │             │         │ 4. **Alignment with the Reference**: The reference confirms that there are no drug-drug interactions, which aligns with the submission's conclusion.                                                                                                                                                                                                                        │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ Since the submission directly and accurately addresses the question based on the provided scenario, it meets the RELEVANCE criterion.                                                                                                                                                                                                                                       │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ Y                                                                                                                                                                                                                                                                                                                                                                           │\n","├────┼─────────────┼─────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n","│  2 │ COHERENCE   │       1 │ 1. **Coherence**: The submission is coherent as it directly addresses the question about drug-drug interactions. It clearly states that there are no interactions to assess since the patient is only taking Lisinopril. This is a logical and straightforward response to the given scenario.                                                                              │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ 2. **Well-Structured**: The submission is well-structured. It begins by addressing the current situation (no interactions due to only one medication) and then provides a forward-looking statement about the importance of considering potential interactions if new medications are introduced. This structure is clear and easy to follow.                               │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ 3. **Organized**: The submission is organized in a logical manner. It first answers the immediate question and then adds a relevant consideration for the future, which helps to provide a complete response without unnecessary information.                                                                                                                               │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ Based on this step-by-step analysis, the submission meets the criteria for coherence, well-structured, and organized.                                                                                                                                                                                                                                                       │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ Y                                                                                                                                                                                                                                                                                                                                                                           │\n","├────┼─────────────┼─────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n","│  3 │ CONCISENESS │       1 │ 1. **Understanding the Criteria**: The criterion to evaluate is \"CONCISENESS,\" which means the submission should be brief and to the point without unnecessary details or repetition.                                                                                                                                                                                       │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ 2. **Analyzing the Submission**: The submission states that there are no drug-drug interactions because the patient is only taking Lisinopril. It also mentions the importance of considering potential interactions if new medications are added in the future.                                                                                                            │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ 3. **Evaluating Conciseness**: The submission is concise. It directly addresses the question by stating there are no current drug-drug interactions and briefly mentions a consideration for the future. There is no unnecessary elaboration or repetition.                                                                                                                 │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ 4. **Conclusion**: The submission meets the criterion of conciseness.                                                                                                                                                                                                                                                                                                       │\n","│    │             │         │                                                                                                                                                                                                                                                                                                                                                                             │\n","│    │             │         │ Y                                                                                                                                                                                                                                                                                                                                                                           │\n","╘════╧═════════════╧═════════╧═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╛\n"]}],"source":["# Gemini\n","\n","gemini_case1_evaluation_results1 = []\n","\n","for criterion, description in custom_criteria.items():\n","    evaluator = load_evaluator(\n","        \"labeled_criteria\",\n","        criteria={criterion: description},\n","        llm=llm_deepseek\n","        )\n","\n","    result = evaluator.evaluate_strings(\n","        prediction=case1_gemini_response1.content,\n","        input=input_query,\n","        reference=case1_ground_truth1\n","    )\n","\n","    gemini_case1_evaluation_results1.append({\n","        \"Criterion\": criterion,\n","        \"Score\": result[\"score\"],\n","        \"Reasoning\": result.get(\"reasoning\", \"No reasoning provided\")\n","    })\n","\n","gemini_case1_evaluation_results1 = pd.DataFrame(gemini_case1_evaluation_results1)\n","\n","print(tabulate(gemini_case1_evaluation_results1,\n","               headers='keys',\n","               tablefmt='fancy_grid'))"]},{"cell_type":"markdown","source":["### Case 1 Question 2"],"metadata":{"id":"WpQW4HdMrEVA"}},{"cell_type":"code","source":["input_query = f\"{case1_system_prompt.strip()}\\n\\nQuestion:\\n{case1_question2}\"\n","\n","# GPT4o\n","gpt_case1_evaluation_results2 = []\n","\n","# Load Evaluators and Run Evaluations\n","for criterion, description in custom_criteria.items():\n","    evaluator = load_evaluator(\n","        \"labeled_criteria\",\n","        criteria={criterion: description},\n","        llm=llm_deepseek\n","        )\n","\n","    result = evaluator.evaluate_strings(\n","        prediction=case1_gpt_response2.content,\n","        input=input_query,\n","        reference=case1_ground_truth2\n","    )\n","\n","    gpt_case1_evaluation_results2.append({\n","        \"Criterion\": criterion,\n","        \"Score\": result[\"score\"],\n","        \"Reasoning\": result.get(\"reasoning\", \"No reasoning provided\")\n","    })\n","\n","gpt_case1_evaluation_results2 = pd.DataFrame(gpt_case1_evaluation_results2)\n","\n","# Gemini\n","gemini_case1_evaluation_results2 = []\n","\n","# Load Evaluators and Run Evaluations\n","for criterion, description in custom_criteria.items():\n","    evaluator = load_evaluator(\n","        \"labeled_criteria\",\n","        criteria={criterion: description},\n","        llm=llm_deepseek)\n","\n","    result = evaluator.evaluate_strings(\n","        prediction=case1_gemini_response2.content,\n","        input=input_query,\n","        reference=case1_ground_truth2\n","    )\n","\n","    gemini_case1_evaluation_results2.append({\n","        \"Criterion\": criterion,\n","        \"Score\": result[\"score\"],\n","        \"Reasoning\": result.get(\"reasoning\", \"No reasoning provided\")\n","    })\n","\n","gemini_case1_evaluation_results2 = pd.DataFrame(gemini_case1_evaluation_results2)"],"metadata":{"id":"fPLr_sARrVbl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Case 2 Question 1"],"metadata":{"id":"lrBzlIIXrHgP"}},{"cell_type":"code","source":["input_query = f\"{case2_system_prompt.strip()}\\n\\nQuestion:\\n{case2_question1}\"\n","\n","# GPT4o\n","gpt_case2_evaluation_results1 = []\n","\n","for criterion, description in custom_criteria.items():\n","    evaluator = load_evaluator(\n","        \"labeled_criteria\",\n","        criteria={criterion: description},\n","        llm=llm_deepseek\n","        )\n","\n","    result = evaluator.evaluate_strings(\n","        prediction=case2_gpt_response1.content,\n","        input=input_query,\n","        reference=case2_ground_truth1\n","    )\n","\n","    gpt_case2_evaluation_results1.append({\n","        \"Criterion\": criterion,\n","        \"Score\": result[\"score\"],\n","        \"Reasoning\": result.get(\"reasoning\", \"No reasoning provided\")\n","    })\n","\n","gpt_case2_evaluation_results1 = pd.DataFrame(gpt_case2_evaluation_results1)\n","\n","# Gemini\n","gemini_case2_evaluation_results1 = []\n","\n","# Load Evaluators and Run Evaluations\n","for criterion, description in custom_criteria.items():\n","\n","    evaluator = load_evaluator(\n","        \"labeled_criteria\",\n","        criteria={criterion: description},\n","        llm=llm_deepseek\n","        )\n","\n","    result = evaluator.evaluate_strings(\n","        prediction=case2_gemini_response1.content,\n","        input=input_query,\n","        reference=case2_ground_truth1\n","    )\n","\n","    gemini_case2_evaluation_results1.append({\n","        \"Criterion\": criterion,\n","        \"Score\": result[\"score\"],\n","        \"Reasoning\": result.get(\"reasoning\", \"No reasoning provided\")\n","    })\n","\n","gemini_case2_evaluation_results1 = pd.DataFrame(gemini_case2_evaluation_results1)"],"metadata":{"id":"MF20jFTWrY48"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Case 2 Question 2"],"metadata":{"id":"D95fzCcvrH9D"}},{"cell_type":"code","source":["input_query = f\"{case2_system_prompt.strip()}\\n\\nQuestion:\\n{case2_question2}\"\n","\n","# GPT4o\n","gpt_case2_evaluation_results2 = []\n","\n","# Load Evaluators and Run Evaluations\n","for criterion, description in custom_criteria.items():\n","    evaluator = load_evaluator(\n","        \"labeled_criteria\",\n","        criteria={criterion: description},\n","        llm=llm_deepseek\n","        )\n","\n","    result = evaluator.evaluate_strings(\n","        prediction=case2_gpt_response2.content,\n","        input=input_query,\n","        reference=case2_ground_truth2\n","    )\n","\n","    gpt_case2_evaluation_results2.append({\n","        \"Criterion\": criterion,\n","        \"Score\": result[\"score\"],\n","        \"Reasoning\": result.get(\"reasoning\", \"No reasoning provided\")\n","    })\n","\n","gpt_case2_evaluation_results2 = pd.DataFrame(gpt_case2_evaluation_results2)\n","\n","# Gemini\n","gemini_case2_evaluation_results2 = []\n","\n","for criterion, description in custom_criteria.items():\n","    evaluator = load_evaluator(\n","        \"labeled_criteria\",\n","        criteria={criterion: description},\n","        llm=llm_deepseek\n","        )\n","\n","    result = evaluator.evaluate_strings(\n","        prediction=case2_gemini_response2.content,\n","        input=input_query,\n","        reference=case2_ground_truth2\n","    )\n","\n","    gemini_case2_evaluation_results2.append({\n","        \"Criterion\": criterion,\n","        \"Score\": result[\"score\"],\n","        \"Reasoning\": result.get(\"reasoning\", \"No reasoning provided\")\n","    })\n","\n","gemini_case2_evaluation_results2 = pd.DataFrame(gemini_case2_evaluation_results2)"],"metadata":{"id":"NOga-CxWrDv-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qqZ39TtIYr3m"},"source":["## 7 NLP-based Metric\n","In this section, we explore three widely used NLP-based metrics for evaluation. These metrics provide objective, quantitative assessments of how closely a model's response aligns with the ground truth.\n","\n","- **F1 Score**: A balance between precision and recall, measuring the exact token matches between the prediction and ground truth.\n","- **ROUGE-L**: Evaluates longest common subsequence overlap between the model's answer and the ground truth. Focuses on recall to assess how much of the ground truth is covered by the model's answer.\n","- **BLEU**: Measures N-gram overlap between the model's answer and the ground truth. Focuses on precision to determine how many n-grams in the model's answer match the ground truth."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QD-jlEXFYr3m"},"outputs":[],"source":["# Import necessary libraries\n","from sklearn.metrics import f1_score\n","from rouge_score import rouge_scorer\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","# F1 Score\n","def compute_f1(pred, truth):\n","    \"\"\"\n","    Computes the F1 Score between the model's prediction and the ground truth.\n","\n","    Parameters:\n","    - pred (str): Model-generated response.\n","    - truth (str): Ground-truth answer.\n","\n","    Returns:\n","    - F1 score (between 0 and 1).\n","    \"\"\"\n","    # Step 1: Tokenize prediction and ground truth into word lists\n","    truth_tokens = truth.split()\n","    pred_tokens = pred.split()\n","\n","    # Step 2: Create a set of all unique tokens from both lists\n","    all_tokens = list(set(truth_tokens + pred_tokens))\n","\n","    # Step 3: Structure binary vectors based on token's presence\n","    truth_vec = [1 if token in truth_tokens else 0 for token in all_tokens]\n","    pred_vec = [1 if token in pred_tokens else 0 for token in all_tokens]\n","\n","    # Step 4: Compute F1 Score\n","    return f1_score(truth_vec, pred_vec, average=\"binary\")\n","\n","# ROUGE\n","def compute_rouge(pred, truth):\n","    \"\"\"\n","    Parameters:\n","    - pred (str): Model-generated response.\n","    - truth (str): Ground-truth reference answer.\n","\n","    Returns:\n","    - float: ROUGE-L F-measure score (between 0 and 1).\n","    \"\"\"\n","\n","    # Step 1: Initialize ROUGE scorer with stemming enabled\n","    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n","\n","    # Step 2: Compute ROUGE-L F1 score\n","    scores = scorer.score(truth, pred)\n","    return scores['rougeL'].fmeasure\n","\n","# BLEU\n","def compute_bleu(pred, truth):\n","    \"\"\"\n","    Parameters:\n","    - pred (str): Model-generated response.\n","    - truth (str): Ground-truth reference answer.\n","\n","    Returns:\n","    - float: BLEU score (between 0 and 1).\n","    \"\"\"\n","\n","    # Step 1: Convert reference and candidate sentences into tokenized lists\n","    reference = [truth.split()]\n","    candidate = pred.split()\n","\n","    # Step 2: Apply smoothing for short sequences\n","    smooth = SmoothingFunction().method1  # Handles short answers better\n","\n","    # Step 3: Compute BLEU score\n","    return sentence_bleu(reference, candidate, smoothing_function=smooth)"]},{"cell_type":"markdown","source":["### Case 1 Question 1"],"metadata":{"id":"OslGhz5WrtIi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EnMDbgIDYr3m","outputId":"428ecf8d-8532-4c7a-cc57-0fa331b02f1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPT Evaluation Results:\n","{'F1 Score': 0.0476, 'ROUGE-L': 0.069, 'BLEU': 0.0035}\n","\n","Gemini Evaluation Results:\n","{'F1 Score': 0.0909, 'ROUGE-L': 0.1455, 'BLEU': 0.0081}\n"]}],"source":["# gpt4o\n","gpt_case1_nlp_evaluation_results1 = {\n","    \"F1 Score\": round(compute_f1(case1_gpt_response1.content, case1_ground_truth1), 4),\n","    \"ROUGE-L\": round(compute_rouge(case1_gpt_response1.content, case1_ground_truth1), 4),\n","    \"BLEU\": round(compute_bleu(case1_gpt_response1.content, case1_ground_truth1), 4)\n","}\n","\n","\n","\n","# Gemini\n","gemini_case1_nlp_evaluation_results1 = {\n","    \"F1 Score\": round(compute_f1(case1_gemini_response1.content, case1_ground_truth1), 4),\n","    \"ROUGE-L\": round(compute_rouge(case1_gemini_response1.content, case1_ground_truth1), 4),\n","    \"BLEU\": round(compute_bleu(case1_gemini_response1.content, case1_ground_truth1), 4)\n","}\n","\n","\n","print(\"GPT Evaluation Results:\")\n","print(gpt_case1_nlp_evaluation_results1)\n","\n","print(\"\\nGemini Evaluation Results:\")\n","print(gemini_case1_nlp_evaluation_results1)"]},{"cell_type":"markdown","source":["### Case 1 Question 2"],"metadata":{"id":"pKx6ER6sr9O_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1GUWCO5LplOs","outputId":"31055e14-7ecb-4c78-b99f-98c21144fc81"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPT Evaluation Results:\n","{'F1 Score': 0.2025, 'ROUGE-L': 0.1455, 'BLEU': 0.0107}\n","\n","Gemini Evaluation Results:\n","{'F1 Score': 0.1486, 'ROUGE-L': 0.1478, 'BLEU': 0.0051}\n"]}],"source":["# gpt4o\n","gpt_case1_nlp_evaluation_results2 = {\n","    \"F1 Score\": round(compute_f1(case1_gpt_response2.content, case1_ground_truth2), 4),\n","    \"ROUGE-L\": round(compute_rouge(case1_gpt_response2.content, case1_ground_truth2), 4),\n","    \"BLEU\": round(compute_bleu(case1_gpt_response2.content, case1_ground_truth2), 4)\n","}\n","\n","# Gemini\n","gemini_case1_nlp_evaluation_results2 = {\n","    \"F1 Score\": round(compute_f1(case1_gemini_response2.content, case1_ground_truth2), 4),\n","    \"ROUGE-L\": round(compute_rouge(case1_gemini_response2.content, case1_ground_truth2), 4),\n","    \"BLEU\": round(compute_bleu(case1_gemini_response2.content, case1_ground_truth2), 4)\n","}\n","\n","print(\"GPT Evaluation Results:\")\n","print(gpt_case1_nlp_evaluation_results2)\n","\n","print(\"\\nGemini Evaluation Results:\")\n","print(gemini_case1_nlp_evaluation_results2)"]},{"cell_type":"markdown","source":["### Case 2 Question 1"],"metadata":{"id":"iNQ4foVXr95Z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jyjwIKWzplOt","outputId":"c9ce05b7-ec95-4dbc-935a-12ed0be8429e"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPT Evaluation Results:\n","{'F1 Score': 0.2079, 'ROUGE-L': 0.1908, 'BLEU': 0.0047}\n","\n","Gemini Evaluation Results:\n","{'F1 Score': 0.2073, 'ROUGE-L': 0.1725, 'BLEU': 0.0064}\n"]}],"source":["# gpt4o\n","gpt_case2_nlp_evaluation_results1 = {\n","    \"F1 Score\": round(compute_f1(case2_gpt_response1.content, case2_ground_truth1), 4),\n","    \"ROUGE-L\": round(compute_rouge(case2_gpt_response1.content, case2_ground_truth1), 4),\n","    \"BLEU\": round(compute_bleu(case2_gpt_response1.content, case2_ground_truth1), 4)\n","}\n","\n","\n","# Gemini\n","gemini_case2_nlp_evaluation_results1 = {\n","    \"F1 Score\": round(compute_f1(case2_gemini_response1.content, case2_ground_truth1), 4),\n","    \"ROUGE-L\": round(compute_rouge(case2_gemini_response1.content, case2_ground_truth1), 4),\n","    \"BLEU\": round(compute_bleu(case2_gemini_response1.content, case2_ground_truth1), 4)\n","}\n","\n","\n","print(\"GPT Evaluation Results:\")\n","print(gpt_case2_nlp_evaluation_results1)\n","\n","print(\"\\nGemini Evaluation Results:\")\n","print(gemini_case2_nlp_evaluation_results1)"]},{"cell_type":"markdown","source":["### Case 2 Question 2"],"metadata":{"id":"kyn1UocOr-c7"}},{"cell_type":"code","source":["# gpt4o\n","gpt_case2_nlp_evaluation_results2 = {\n","    \"F1 Score\": round(compute_f1(case2_gpt_response2.content, case2_ground_truth2), 4),\n","    \"ROUGE-L\": round(compute_rouge(case2_gpt_response2.content, case2_ground_truth2), 4),\n","    \"BLEU\": round(compute_bleu(case2_gpt_response2.content, case2_ground_truth2), 4)\n","}\n","\n","\n","# Gemini\n","gemini_case2_nlp_evaluation_results2 = {\n","    \"F1 Score\": round(compute_f1(case2_gemini_response2.content, case2_ground_truth2), 4),\n","    \"ROUGE-L\": round(compute_rouge(case2_gemini_response2.content, case2_ground_truth2), 4),\n","    \"BLEU\": round(compute_bleu(case2_gemini_response2.content, case2_ground_truth2), 4)\n","}"],"metadata":{"id":"hJfh4LXqrsmm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KfouPAIxYr3m"},"source":["## 8\\. Comparative Analysis\n","In this section, we create summaries of the evaluation results across different approaches. You can use the summaries for comparative analysis and determine which foundation model to use for your application.\n","\n","Note: this lab does not include manual evaluation by human. For high-stakes applications such as Medical AI or legal AI, you may want to have manual evaluation by experts, Comparing expert evaluaion with the automated approaches covered in this lab can help create a gold standard for quality control. However, it is often time-consuming and may introduce subjectivity.Therefore, a hybrid approach, combining automated metrics with expert review, is recommended for critical applications."]},{"cell_type":"markdown","source":["### Case 1 Question 1"],"metadata":{"id":"-X1XdEsUs5pX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XfiWKUVsplOr"},"outputs":[],"source":["# Extract Total Cost & Response Time for GPT-4o\n","gpt_case1_total_cost1 = gpt_case1_usages1[0][\"Total Cost (USD)\"]\n","gpt_case1_response_time1 = gpt_case1_usages1[0][\"Response Time (s)\"]\n","\n","# Extract Total Cost and Response Time for Gemini 2.0 Flash\n","gemini_case1_total_cost1 = gemini_case1_usages1[0][\"Total Cost (USD)\"]\n","gemini_case1_response_time1 = gemini_case1_usages1[0][\"Response Time (s)\"]\n","\n","# Extract Cosine Similarity Scores\n","gpt_case1_cosine_similarity1 = case1_cosine_similarities1[case1_cosine_similarities1[\"Model\"] == \"GPT-4o\"][\"Cosine Similarity\"].values[0]\n","gemini_case1_cosine_similarity1 = case1_cosine_similarities1[case1_cosine_similarities1[\"Model\"] == \"Gemini 2.0 Flash\"][\"Cosine Similarity\"].values[0]\n","\n","# Extract LLM-based Criterion Scores GPT\n","gpt_case1_criterion_scores1 = {}\n","for _, row in gpt_case1_evaluation_results1.iterrows():\n","    gpt_case1_criterion_scores1[row[\"Criterion\"]] = row[\"Score\"]\n","\n","# Extract Criterion Scores for Gemini\n","gemini_case1_criterion_scores1 = {}\n","for _, row in gemini_case1_evaluation_results1.iterrows():\n","    gemini_case1_criterion_scores1[row[\"Criterion\"]] = row[\"Score\"]\n","\n","\n","# Combine all metrics into a summary table\n","case1_table1_of_metrics = pd.DataFrame({\n","    \"Model\": [\"GPT-4o\", \"Gemini 2.0 Flash\"],\n","    \"Cosine Similarity\": [gpt_case1_cosine_similarity1, gemini_case1_cosine_similarity1],\n","\n","    # Dynamically add LLM-based criterion scores\n","    **{f\"{criterion} Score\": [gpt_case1_criterion_scores1.get(criterion, None), gemini_case1_criterion_scores1.get(criterion, None)]\n","       for criterion in gpt_case1_criterion_scores1.keys()},\n","\n","    # NLP-based evaluation metrics\n","    \"F1 Score\": [gpt_case1_nlp_evaluation_results1[\"F1 Score\"], gemini_case1_nlp_evaluation_results1[\"F1 Score\"]],\n","    \"ROUGE-L\": [gpt_case1_nlp_evaluation_results1[\"ROUGE-L\"], gemini_case1_nlp_evaluation_results1[\"ROUGE-L\"]],\n","    \"BLEU\": [gpt_case1_nlp_evaluation_results1[\"BLEU\"], gemini_case1_nlp_evaluation_results1[\"BLEU\"]],\n","\n","     # Efficiency metrics\n","    \"Total Cost (USD)\": [gpt_case1_total_cost1, gemini_case1_total_cost1],\n","    \"Response Time (s)\": [gpt_case1_response_time1, gemini_case1_response_time1]\n","})\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00qHxnNoplOr","outputId":"70fc4f58-2e32-48a4-f83c-181c78c85c99"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Cosine Similarity</th>\n","      <th>CORRECTNESS Score</th>\n","      <th>RELEVANCE Score</th>\n","      <th>COHERENCE Score</th>\n","      <th>CONCISENESS Score</th>\n","      <th>F1 Score</th>\n","      <th>ROUGE-L</th>\n","      <th>BLEU</th>\n","      <th>Total Cost (USD)</th>\n","      <th>Response Time (s)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GPT-4o</td>\n","      <td>0.443316</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.0476</td>\n","      <td>0.0690</td>\n","      <td>0.0035</td>\n","      <td>0.002107</td>\n","      <td>3.31</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gemini 2.0 Flash</td>\n","      <td>0.510786</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0909</td>\n","      <td>0.1455</td>\n","      <td>0.0081</td>\n","      <td>0.000051</td>\n","      <td>0.92</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Model  Cosine Similarity  CORRECTNESS Score  RELEVANCE Score  \\\n","0            GPT-4o           0.443316                  1                1   \n","1  Gemini 2.0 Flash           0.510786                  1                1   \n","\n","   COHERENCE Score  CONCISENESS Score  F1 Score  ROUGE-L    BLEU  \\\n","0                1                  0    0.0476   0.0690  0.0035   \n","1                1                  1    0.0909   0.1455  0.0081   \n","\n","   Total Cost (USD)  Response Time (s)  \n","0          0.002107               3.31  \n","1          0.000051               0.92  "]},"execution_count":147,"metadata":{},"output_type":"execute_result"}],"source":["case1_table1_of_metrics"]},{"cell_type":"markdown","source":["### Case 1 Question 2"],"metadata":{"id":"CjU09JYUs9Ji"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UOti93xkplOs","outputId":"4efcb3fc-8d52-4590-a135-3b7eca8c9275"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Cosine Similarity</th>\n","      <th>CORRECTNESS Score</th>\n","      <th>RELEVANCE Score</th>\n","      <th>COHERENCE Score</th>\n","      <th>CONCISENESS Score</th>\n","      <th>F1 Score</th>\n","      <th>ROUGE-L</th>\n","      <th>BLEU</th>\n","      <th>Total Cost (USD)</th>\n","      <th>Response Time (s)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GPT-4o</td>\n","      <td>0.701854</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.2025</td>\n","      <td>0.1455</td>\n","      <td>0.0107</td>\n","      <td>0.002678</td>\n","      <td>7.22</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gemini 2.0 Flash</td>\n","      <td>0.697518</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.1486</td>\n","      <td>0.1478</td>\n","      <td>0.0051</td>\n","      <td>0.000097</td>\n","      <td>2.25</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Model  Cosine Similarity  CORRECTNESS Score  RELEVANCE Score  \\\n","0            GPT-4o           0.701854                  1                1   \n","1  Gemini 2.0 Flash           0.697518                  1                1   \n","\n","   COHERENCE Score  CONCISENESS Score  F1 Score  ROUGE-L    BLEU  \\\n","0                1                  0    0.2025   0.1455  0.0107   \n","1                1                  0    0.1486   0.1478  0.0051   \n","\n","   Total Cost (USD)  Response Time (s)  \n","0          0.002678               7.22  \n","1          0.000097               2.25  "]},"execution_count":163,"metadata":{},"output_type":"execute_result"}],"source":["gpt_case1_total_cost2 = gpt_case1_usages2[0][\"Total Cost (USD)\"]\n","gpt_case1_response_time2 = gpt_case1_usages2[0][\"Response Time (s)\"]\n","\n","gemini_case1_total_cost2 = gemini_case1_usages2[0][\"Total Cost (USD)\"]\n","gemini_case1_response_time2 = gemini_case1_usages2[0][\"Response Time (s)\"]\n","\n","gpt_case1_cosine_similarity2 = case1_cosine_similarities2[case1_cosine_similarities2[\"Model\"] == \"GPT-4o\"][\"Cosine Similarity\"].values[0]\n","gemini_case1_cosine_similarity2 = case1_cosine_similarities2[case1_cosine_similarities2[\"Model\"] == \"Gemini 2.0 Flash\"][\"Cosine Similarity\"].values[0]\n","\n","gpt_case1_criterion_scores2 = {}\n","for _, row in gpt_case1_evaluation_results2.iterrows():\n","    gpt_case1_criterion_scores2[row[\"Criterion\"]] = row[\"Score\"]\n","\n","gemini_case1_criterion_scores2 = {}\n","for _, row in gemini_case1_evaluation_results2.iterrows():\n","    gemini_case1_criterion_scores2[row[\"Criterion\"]] = row[\"Score\"]\n","\n","case1_table2_of_metrics = pd.DataFrame({\n","    \"Model\": [\"GPT-4o\", \"Gemini 2.0 Flash\"],\n","    \"Cosine Similarity\": [gpt_case1_cosine_similarity2, gemini_case1_cosine_similarity2],\n","\n","    **{f\"{criterion} Score\": [gpt_case1_criterion_scores2.get(criterion, None), gemini_case1_criterion_scores2.get(criterion, None)]\n","       for criterion in gpt_case1_criterion_scores2.keys()},\n","\n","    \"F1 Score\": [gpt_case1_nlp_evaluation_results2[\"F1 Score\"], gemini_case1_nlp_evaluation_results2[\"F1 Score\"]],\n","    \"ROUGE-L\": [gpt_case1_nlp_evaluation_results2[\"ROUGE-L\"], gemini_case1_nlp_evaluation_results2[\"ROUGE-L\"]],\n","    \"BLEU\": [gpt_case1_nlp_evaluation_results2[\"BLEU\"], gemini_case1_nlp_evaluation_results2[\"BLEU\"]],\n","\n","    \"Total Cost (USD)\": [gpt_case1_total_cost2, gemini_case1_total_cost2],\n","    \"Response Time (s)\": [gpt_case1_response_time2, gemini_case1_response_time2]\n","})\n","\n","case1_table2_of_metrics"]},{"cell_type":"markdown","source":["### Case 2 Question 1"],"metadata":{"id":"m_aF5n1Ts9iv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lkUhfKahplOw","outputId":"3d7876eb-120a-4b43-d98b-06e8dcb65c92"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Cosine Similarity</th>\n","      <th>CORRECTNESS Score</th>\n","      <th>RELEVANCE Score</th>\n","      <th>COHERENCE Score</th>\n","      <th>CONCISENESS Score</th>\n","      <th>F1 Score</th>\n","      <th>ROUGE-L</th>\n","      <th>BLEU</th>\n","      <th>Total Cost (USD)</th>\n","      <th>Response Time (s)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GPT-4o</td>\n","      <td>0.781913</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.2079</td>\n","      <td>0.1908</td>\n","      <td>0.0047</td>\n","      <td>0.003298</td>\n","      <td>4.76</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gemini 2.0 Flash</td>\n","      <td>0.763158</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.2073</td>\n","      <td>0.1725</td>\n","      <td>0.0064</td>\n","      <td>0.000121</td>\n","      <td>2.24</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Model  Cosine Similarity  CORRECTNESS Score  RELEVANCE Score  \\\n","0            GPT-4o           0.781913                  1                1   \n","1  Gemini 2.0 Flash           0.763158                  1                1   \n","\n","   COHERENCE Score  CONCISENESS Score  F1 Score  ROUGE-L    BLEU  \\\n","0                1                  0    0.2079   0.1908  0.0047   \n","1                1                  1    0.2073   0.1725  0.0064   \n","\n","   Total Cost (USD)  Response Time (s)  \n","0          0.003298               4.76  \n","1          0.000121               2.24  "]},"execution_count":170,"metadata":{},"output_type":"execute_result"}],"source":["gpt_case2_total_cost1 = gpt_case2_usages1[0][\"Total Cost (USD)\"]\n","gpt_case2_response_time1 = gpt_case2_usages1[0][\"Response Time (s)\"]\n","\n","gemini_case2_total_cost1 = gemini_case2_usages1[0][\"Total Cost (USD)\"]\n","gemini_case2_response_time1 = gemini_case2_usages1[0][\"Response Time (s)\"]\n","\n","gpt_case2_cosine_similarity1 = case2_cosine_similarities1[case2_cosine_similarities1[\"Model\"] == \"GPT-4o\"][\"Cosine Similarity\"].values[0]\n","gemini_case2_cosine_similarity1 = case2_cosine_similarities1[case2_cosine_similarities1[\"Model\"] == \"Gemini 2.0 Flash\"][\"Cosine Similarity\"].values[0]\n","\n","gpt_case2_criterion_scores1 = {}\n","for _, row in gpt_case2_evaluation_results1.iterrows():\n","    gpt_case2_criterion_scores1[row[\"Criterion\"]] = row[\"Score\"]\n","\n","gemini_case2_criterion_scores1 = {}\n","for _, row in gemini_case2_evaluation_results1.iterrows():\n","    gemini_case2_criterion_scores1[row[\"Criterion\"]] = row[\"Score\"]\n","\n","case2_table1_of_metrics = pd.DataFrame({\n","    \"Model\": [\"GPT-4o\", \"Gemini 2.0 Flash\"],\n","    \"Cosine Similarity\": [gpt_case2_cosine_similarity1, gemini_case2_cosine_similarity1],\n","\n","    **{f\"{criterion} Score\": [gpt_case2_criterion_scores1.get(criterion, None), gemini_case2_criterion_scores1.get(criterion, None)]\n","       for criterion in gpt_case2_criterion_scores1.keys()},\n","\n","    \"F1 Score\": [gpt_case2_nlp_evaluation_results1[\"F1 Score\"], gemini_case2_nlp_evaluation_results1[\"F1 Score\"]],\n","    \"ROUGE-L\": [gpt_case2_nlp_evaluation_results1[\"ROUGE-L\"], gemini_case2_nlp_evaluation_results1[\"ROUGE-L\"]],\n","    \"BLEU\": [gpt_case2_nlp_evaluation_results1[\"BLEU\"], gemini_case2_nlp_evaluation_results1[\"BLEU\"]],\n","\n","    \"Total Cost (USD)\": [gpt_case2_total_cost1, gemini_case2_total_cost1],\n","    \"Response Time (s)\": [gpt_case2_response_time1, gemini_case2_response_time1]\n","\n","})\n","\n","case2_table1_of_metrics"]},{"cell_type":"markdown","source":["### Case 2 Question 2"],"metadata":{"id":"wakbVBqbs9yM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NtLxt5B1plOw","outputId":"1327c23a-027b-4d78-cc9f-5ae2dacc43d6"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Cosine Similarity</th>\n","      <th>CORRECTNESS Score</th>\n","      <th>RELEVANCE Score</th>\n","      <th>COHERENCE Score</th>\n","      <th>CONCISENESS Score</th>\n","      <th>F1 Score</th>\n","      <th>ROUGE-L</th>\n","      <th>BLEU</th>\n","      <th>Total Cost (USD)</th>\n","      <th>Response Time (s)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GPT-4o</td>\n","      <td>0.705067</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.2211</td>\n","      <td>0.1308</td>\n","      <td>0.0027</td>\n","      <td>0.002868</td>\n","      <td>4.90</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Gemini 2.0 Flash</td>\n","      <td>0.653491</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.1685</td>\n","      <td>0.1074</td>\n","      <td>0.0029</td>\n","      <td>0.000109</td>\n","      <td>2.16</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Model  Cosine Similarity  CORRECTNESS Score  RELEVANCE Score  \\\n","0            GPT-4o           0.705067                  1                1   \n","1  Gemini 2.0 Flash           0.653491                  0                1   \n","\n","   COHERENCE Score  CONCISENESS Score  F1 Score  ROUGE-L    BLEU  \\\n","0                1                  0    0.2211   0.1308  0.0027   \n","1                1                  1    0.1685   0.1074  0.0029   \n","\n","   Total Cost (USD)  Response Time (s)  \n","0          0.002868               4.90  \n","1          0.000109               2.16  "]},"execution_count":178,"metadata":{},"output_type":"execute_result"}],"source":["gpt_case2_total_cost2 = gpt_case2_usages2[0][\"Total Cost (USD)\"]\n","gpt_case2_response_time2 = gpt_case2_usages2[0][\"Response Time (s)\"]\n","\n","gemini_case2_total_cost2 = gemini_case2_usages2[0][\"Total Cost (USD)\"]\n","gemini_case2_response_time2 = gemini_case2_usages2[0][\"Response Time (s)\"]\n","\n","gpt_case2_cosine_similarity2 = case2_cosine_similarities2[case2_cosine_similarities2[\"Model\"] == \"GPT-4o\"][\"Cosine Similarity\"].values[0]\n","gemini_case2_cosine_similarity2 = case2_cosine_similarities2[case2_cosine_similarities2[\"Model\"] == \"Gemini 2.0 Flash\"][\"Cosine Similarity\"].values[0]\n","\n","gpt_case2_criterion_scores2 = {}\n","for _, row in gpt_case2_evaluation_results2.iterrows():\n","    gpt_case2_criterion_scores2[row[\"Criterion\"]] = row[\"Score\"]\n","\n","gemini_case2_criterion_scores2 = {}\n","for _, row in gemini_case2_evaluation_results2.iterrows():\n","    gemini_case2_criterion_scores2[row[\"Criterion\"]] = row[\"Score\"]\n","\n","case2_table2_of_metrics = pd.DataFrame({\n","    \"Model\": [\"GPT-4o\", \"Gemini 2.0 Flash\"],\n","    \"Cosine Similarity\": [gpt_case2_cosine_similarity2, gemini_case2_cosine_similarity2],\n","\n","    **{f\"{criterion} Score\": [gpt_case2_criterion_scores2.get(criterion, None), gemini_case2_criterion_scores2.get(criterion, None)]\n","       for criterion in gpt_case2_criterion_scores2.keys()},\n","\n","    \"F1 Score\": [gpt_case2_nlp_evaluation_results2[\"F1 Score\"], gemini_case2_nlp_evaluation_results2[\"F1 Score\"]],\n","    \"ROUGE-L\": [gpt_case2_nlp_evaluation_results2[\"ROUGE-L\"], gemini_case2_nlp_evaluation_results2[\"ROUGE-L\"]],\n","    \"BLEU\": [gpt_case2_nlp_evaluation_results2[\"BLEU\"], gemini_case2_nlp_evaluation_results2[\"BLEU\"]],\n","\n","    \"Total Cost (USD)\": [gpt_case2_total_cost2, gemini_case2_total_cost2],\n","    \"Response Time (s)\": [gpt_case2_response_time2, gemini_case2_response_time2]\n","\n","})\n","\n","case2_table2_of_metrics"]},{"cell_type":"markdown","source":["### Final summary\n","Let's aggregate evaluation results across multiple cases for GPT-4o and Gemini 2.0 Flash and create a final summary of averaged metrics."],"metadata":{"id":"vJiSLb0htbfA"}},{"cell_type":"code","source":["def compute_case_summary(tables, model_name):\n","\n","   # Step 1: Filter data for the specified model across all tables\n","   model_df = pd.concat([df[df[\"Model\"] == model_name] for df in tables], ignore_index=True)\n","\n","   # Step 2: Define the list of metrics to be averaged\n","   metrics = [\"Cosine Similarity\", \"CORRECTNESS Score\", \"RELEVANCE Score\",\n","              \"COHERENCE Score\", \"CONCISENESS Score\", \"F1 Score\", \"ROUGE-L\", \"BLEU\"]\n","\n","   # Compute average values across all cases for each metric\n","   averaging_metrics = {f\"Average {m}\": model_df[m].mean() for m in metrics}\n","\n","   # Step 3: Define the list of additive metrics for Total Cost and Response Time\n","   additive_metrics = {\n","       \"Case-wise Average Cost (USD)\": model_df[\"Total Cost (USD)\"].sum(),\n","       \"Case-wise Average Time (s)\": model_df[\"Response Time (s)\"].sum()\n","   }\n","\n","   # Merge both types of metrics into a single summary\n","   return averaging_metrics | additive_metrics\n","\n","# Prepare evaluation tables for each case\n","case1_tables = [case1_table1_of_metrics, case1_table2_of_metrics]\n","case2_tables = [case2_table1_of_metrics, case2_table2_of_metrics]\n","\n","# Compute summary for each model acrss cases\n","summaries = {\n","   \"case1\": {m: compute_case_summary(case1_tables, m) for m in [\"GPT-4o\", \"Gemini 2.0 Flash\"]},\n","   \"case2\": {m: compute_case_summary(case2_tables, m) for m in [\"GPT-4o\", \"Gemini 2.0 Flash\"]}\n","}\n","\n","# Compute the final average summary across all cases\n","final_summary_df = pd.DataFrame.from_dict({\n","   model: {k: (summaries[\"case1\"][model][k] + summaries[\"case2\"][model][k]) / 2\n","          for k in summaries[\"case1\"][model].keys()\n","          }\n","   for model in [\"GPT-4o\", \"Gemini 2.0 Flash\"]\n","}, orient=\"index\")"],"metadata":{"id":"G_6wXSixVbuB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_summary_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":125},"id":"jpC58BBTVcvJ","executionInfo":{"status":"ok","timestamp":1739038179490,"user_tz":480,"elapsed":15,"user":{"displayName":"Yuri Yu","userId":"07815337368675902379"}},"outputId":"69dabd6b-35db-4940-abb3-48814cd46932"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  Average Cosine Similarity  Average CORRECTNESS Score  \\\n","GPT-4o                             0.658038                       1.00   \n","Gemini 2.0 Flash                   0.656238                       0.75   \n","\n","                  Average RELEVANCE Score  Average COHERENCE Score  \\\n","GPT-4o                                1.0                      1.0   \n","Gemini 2.0 Flash                      1.0                      1.0   \n","\n","                  Average CONCISENESS Score  Average F1 Score  \\\n","GPT-4o                                 0.00          0.169775   \n","Gemini 2.0 Flash                       0.75          0.153825   \n","\n","                  Average ROUGE-L  Average BLEU  Case-wise Average Cost (USD)  \\\n","GPT-4o                   0.134025      0.005400                      0.005475   \n","Gemini 2.0 Flash         0.143300      0.005625                      0.000189   \n","\n","                  Case-wise Average Time (s)  \n","GPT-4o                                10.095  \n","Gemini 2.0 Flash                       3.785  "],"text/html":["\n","  <div id=\"df-173c063e-8b22-4da2-a17d-4547e94dc976\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Average Cosine Similarity</th>\n","      <th>Average CORRECTNESS Score</th>\n","      <th>Average RELEVANCE Score</th>\n","      <th>Average COHERENCE Score</th>\n","      <th>Average CONCISENESS Score</th>\n","      <th>Average F1 Score</th>\n","      <th>Average ROUGE-L</th>\n","      <th>Average BLEU</th>\n","      <th>Case-wise Average Cost (USD)</th>\n","      <th>Case-wise Average Time (s)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>GPT-4o</th>\n","      <td>0.658038</td>\n","      <td>1.00</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.00</td>\n","      <td>0.169775</td>\n","      <td>0.134025</td>\n","      <td>0.005400</td>\n","      <td>0.005475</td>\n","      <td>10.095</td>\n","    </tr>\n","    <tr>\n","      <th>Gemini 2.0 Flash</th>\n","      <td>0.656238</td>\n","      <td>0.75</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.75</td>\n","      <td>0.153825</td>\n","      <td>0.143300</td>\n","      <td>0.005625</td>\n","      <td>0.000189</td>\n","      <td>3.785</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-173c063e-8b22-4da2-a17d-4547e94dc976')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-173c063e-8b22-4da2-a17d-4547e94dc976 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-173c063e-8b22-4da2-a17d-4547e94dc976');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2aaea754-88b5-42e0-be70-220c9b819f2d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2aaea754-88b5-42e0-be70-220c9b819f2d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2aaea754-88b5-42e0-be70-220c9b819f2d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_08798176-93ac-48d2-9115-a7d8d031730b\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_summary_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_08798176-93ac-48d2-9115-a7d8d031730b button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('final_summary_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"final_summary_df","summary":"{\n  \"name\": \"final_summary_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Average Cosine Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0012722618760499169,\n        \"min\": 0.65623825,\n        \"max\": 0.6580375,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.65623825,\n          0.6580375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average CORRECTNESS Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1767766952966369,\n        \"min\": 0.75,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.75,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average RELEVANCE Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average COHERENCE Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average CONCISENESS Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5303300858899106,\n        \"min\": 0.0,\n        \"max\": 0.75,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011278353159925448,\n        \"min\": 0.153825,\n        \"max\": 0.169775,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.153825\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average ROUGE-L\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0065584153955052125,\n        \"min\": 0.134025,\n        \"max\": 0.14329999999999998,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.14329999999999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average BLEU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00015909902576697284,\n        \"min\": 0.0054,\n        \"max\": 0.005625,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.005625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Case-wise Average Cost (USD)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003738119998742683,\n        \"min\": 0.00018899999999999999,\n        \"max\": 0.0054754999999999995,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.00018899999999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Case-wise Average Time (s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.461843789287114,\n        \"min\": 3.785,\n        \"max\": 10.094999999999999,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3.785\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]}],"metadata":{"kernelspec":{"display_name":"genai_class_venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}